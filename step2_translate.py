import json
import re
from openai import OpenAI
import time

# ===== é…ç½® =====
API_BASE = "https://hackathon.boson.ai/v1"
API_KEY = "bai-C8daJQcbo2sMbwgr9aTNmCZM4C1zliRyWLPNA3cRGGksCagH"
MODEL_NAME = "Qwen3-32B-non-thinking-Hackathon"

INPUT_JSON = "transcription_with_timestamps.json"
OUTPUT_JSON = "translated_with_timestamps.json"

# ===== ç›®æ ‡è¯­è¨€é…ç½® =====
SOURCE_LANG = "Chinese"
TARGET_LANG = "English"

client = OpenAI(api_key=API_KEY, base_url=API_BASE)


# =============================================================
# å·¥å…·å‡½æ•°
# =============================================================
def clean_text(text: str) -> str:
    """æ¸…ç†ç¿»è¯‘æ–‡æœ¬"""
    text = re.sub(r'[\u4e00-\u9fff]+', '', text)  # ç§»é™¤ä¸­æ–‡
    text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ã€Šã€‹ã€ã€‘ï¼ˆï¼‰]', '', text)
    text = ' '.join(text.split())
    return text.strip()


# =============================================================
# ç¬¬ä¸€æ­¥ï¼šåˆ†æè§†é¢‘å†…å®¹é£æ ¼
# =============================================================
def analyze_content_style(sentences: list) -> dict:
    print("\n" + "=" * 80)
    print("ğŸ” åˆ†æè§†é¢‘å†…å®¹é£æ ¼...")
    print("=" * 80)

    # æŠ½æ ·å‡ å¥åˆ†æé£æ ¼
    sample_texts = [s.get("text", "").strip() for s in sentences[:5]]
    sample_texts += [s.get("text", "").strip() for s in sentences[-2:]]
    sample = "\n".join([f"{i+1}. {t}" for i, t in enumerate(sample_texts) if t])

    prompt = f"""Analyze this video transcript sample and identify:

SAMPLE TEXT:
{sample}

Provide a brief analysis (2-3 sentences):
1. Content type (e.g. comedy, educational, narrative, etc.)
2. Tone and style (formal, casual, humorous, etc.)
3. Any special traits (wordplay, technical terms, etc.)

Keep it concise:"""

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "You are a content analyst."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=200
        )
        analysis = response.choices[0].message.content.strip()
        print(f"\nğŸ“Š å†…å®¹åˆ†æ:\n{analysis}\n")
        return {"analysis": analysis}
    except Exception as e:
        print(f"âš ï¸ åˆ†æå¤±è´¥: {e}")
        return {"analysis": "General video content."}


# =============================================================
# ç¬¬äºŒæ­¥ï¼šæ•´æ®µç¿»è¯‘ï¼ˆä¿ç•™æ—¶é—´æˆ³ï¼‰
# =============================================================
def translate_full_script(sentences: list, style_info: dict) -> list:
    print("\n" + "=" * 80)
    print(f"ğŸ“ ç¿»è¯‘å…¨æ–‡ ({SOURCE_LANG} â†’ {TARGET_LANG})")
    print("=" * 80)

    full_script = []
    for i, s in enumerate(sentences):
        text = s.get("text", "").strip()
        if text:
            full_script.append(f"{i+1}. {text}")
    script_text = "\n".join(full_script)

    style_context = style_info.get("analysis", "")

    prompt = f"""You are translating a video transcript from {SOURCE_LANG} to {TARGET_LANG}.

CONTENT ANALYSIS:
{style_context}

FULL TRANSCRIPT:
{script_text}

TRANSLATION REQUIREMENTS:
1. Translate naturally and fluently as if it were originally in {TARGET_LANG}.
2. Keep the same tone, humor, and emotional style.
3. Output numbered sentences exactly as in the input (1., 2., 3., ...).
4. Only return the translated lines â€” do not repeat the Chinese.

Begin translation:"""

    try:
        print("\nğŸ¤– æ­£åœ¨ç¿»è¯‘ä¸­...")
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "You are a professional translator for video subtitles."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
            max_tokens=2000
        )

        translation = response.choices[0].message.content.strip()
        lines = []
        for line in translation.split("\n"):
            line = line.strip()
            if not line:
                continue
            # å»æ‰åºå·ï¼ˆæ”¯æŒ 1. / 1) / 1ã€ç­‰ï¼‰
            line = re.sub(r"^\d+[\.\)ã€]\s*", "", line)
            line = clean_text(line)
            if line and len(line) > 1:
                lines.append(line)

        print(f"âœ… æˆåŠŸç¿»è¯‘ {len(lines)} å¥\n")
        print("ç¿»è¯‘é¢„è§ˆ:")
        print("-" * 80)
        for i in range(min(5, len(lines))):
            print(f"{i+1}. {lines[i]}")
        if len(lines) > 5:
            print(f"... (è¿˜æœ‰ {len(lines)-5} å¥)")
        print("-" * 80)

        return lines
    except Exception as e:
        print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
        return []


# =============================================================
# ç¬¬ä¸‰æ­¥ï¼šé•¿åº¦å¾®è°ƒï¼ˆå¹¶æ‰“å°å‰åå¯¹æ¯”ï¼‰
# =============================================================
def adjust_by_length(sentences: list, translations: list) -> list:
    print("\n" + "=" * 80)
    print("âœï¸  è°ƒæ•´è‹±æ–‡é•¿åº¦ï¼ˆä¿æŒä¸ä¸­æ–‡æ¥è¿‘ï¼Œå·®è·â‰¤3è¯ï¼‰")
    print("=" * 80)

    adjusted = []
    for i, sent in enumerate(sentences):
        if i >= len(translations):
            continue

        text_zh = sent.get("text", "")
        text_en = translations[i]

        target_words = max(3, len(text_zh) // 3)
        current_words = len(text_en.split())

        # è¾“å‡ºåŸå§‹ç¿»è¯‘
        print(f"\n[{i+1}] åŸæ–‡: {text_zh}")
        print(f"     åˆè¯‘: {text_en}")
        print(f"     è¯æ•°: {current_words}, ç›®æ ‡: {target_words}")

        if abs(current_words - target_words) <= 3:
            adjusted_text = text_en
            print("     âœ… æ— éœ€è°ƒæ•´")
        else:
            print("     ğŸ”§ è°ƒæ•´ä¸­...")
            try:
                prompt = f"""Adjust this English sentence so that its length (word count) is close to {target_words} words.
Keep the same meaning, tone, and fluency.
Sentence: "{text_en}"
Output only the adjusted sentence."""
                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[
                        {"role": "system", "content": "You are a fluent English editor."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.4,
                    max_tokens=100
                )
                adjusted_text = clean_text(response.choices[0].message.content.strip())
                if not adjusted_text:
                    adjusted_text = text_en
                print(f"     âœ… è°ƒæ•´å: {adjusted_text}")
            except Exception as e:
                print(f"     âš ï¸ è°ƒæ•´å¤±è´¥: {e}")
                adjusted_text = text_en

            time.sleep(0.4)

        adjusted.append(adjusted_text)

    return adjusted


# =============================================================
# ä¸»æµç¨‹
# =============================================================
def main():
    print("=" * 80)
    print("ğŸ¬ Step 2: ä¸­æ–‡ â†’ è‹±æ–‡ç¿»è¯‘ï¼ˆä¿ç•™æ—¶é—´æˆ³ç»“æ„ + å¯¹æ¯”è¾“å‡ºï¼‰")
    print("=" * 80)

    try:
        with open(INPUT_JSON, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–è¾“å…¥æ–‡ä»¶: {e}")
        return

    result = data[0]
    sentences = result.get("sentence_info", [])
    print(f"âœ… åŠ è½½ {len(sentences)} ä¸ªå¥å­")

    # 1ï¸âƒ£ å†…å®¹é£æ ¼åˆ†æ
    style_info = analyze_content_style(sentences)

    # 2ï¸âƒ£ ç¿»è¯‘
    translations = translate_full_script(sentences, style_info)
    if not translations:
        print("âŒ ç¿»è¯‘å¤±è´¥")
        return

    # 3ï¸âƒ£ é•¿åº¦å¾®è°ƒ + è¾“å‡ºå¯¹æ¯”
    adjusted = adjust_by_length(sentences, translations)

    # 4ï¸âƒ£ æ„å»ºè¾“å‡ºï¼šä¿ç•™ start/end/duration
    translated = []
    for i, s in enumerate(sentences):
        translated.append({
            "start": s.get("start", 0),
            "end": s.get("end", 0),
            "duration": round(s.get("end", 0) - s.get("start", 0), 2),
            "text_zh": s.get("text", ""),
            "text_en": adjusted[i] if i < len(adjusted) else ""
        })

    output = [{
        "key": result.get("key", "unknown"),
        "sentence_info": translated,
        "metadata": {
            "source_language": SOURCE_LANG,
            "target_language": TARGET_LANG,
            "model": MODEL_NAME,
            "method": "length_adjust_no_timestamp_with_diff"
        }
    }]

    with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print("\nğŸ’¾ ç¿»è¯‘å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³:", OUTPUT_JSON)
    print("=" * 80)


if __name__ == "__main__":
    main()
