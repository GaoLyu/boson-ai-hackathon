import json
import re
from openai import OpenAI
import time

# ===== é…ç½® =====
API_BASE = "https://hackathon.boson.ai/v1"
API_KEY = "bai-C8daJQcbo2sMbwgr9aTNmCZM4C1zliRyWLPNA3cRGGksCagH"
MODEL_NAME = "Qwen3-32B-non-thinking-Hackathon"

INPUT_JSON = "transcription_with_timestamps.json"
OUTPUT_JSON = "translated_with_timestamps.json"

# ===== ç›®æ ‡è¯­è¨€é…ç½® =====
SOURCE_LANG = "Chinese"
TARGET_LANG = "English"

client = OpenAI(api_key=API_KEY, base_url=API_BASE)

def clean_text(text: str) -> str:
    """æ¸…ç†ç¿»è¯‘æ–‡æœ¬ï¼Œä¿ç•™ç›®æ ‡è¯­è¨€å†…å®¹"""
    # ç§»é™¤ä¸­æ–‡
    text = re.sub(r'[\u4e00-\u9fff]+', '', text)
    # ç§»é™¤ä¸­æ–‡æ ‡ç‚¹
    text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ã€Šã€‹ã€ã€‘ï¼ˆï¼‰]', '', text)
    # æ¸…ç†å¤šä½™ç©ºæ ¼
    text = ' '.join(text.split())
    return text.strip()

# ===== ç¬¬ä¸€æ­¥ï¼šåˆ†æå†…å®¹é£æ ¼ =====
def analyze_content_style(sentences: list) -> dict:
    """
    åˆ†ææºæ–‡æœ¬çš„é£æ ¼å’Œç±»å‹
    """
    print("\n" + "="*80)
    print("ğŸ” åˆ†æè§†é¢‘å†…å®¹é£æ ¼...")
    print("="*80)
    
    # å–å‰5å¥å’Œå2å¥ä½œä¸ºæ ·æœ¬
    sample_texts = [s.get("text", "").strip() for s in sentences[:5]]
    sample_texts += [s.get("text", "").strip() for s in sentences[-2:]]
    sample = "\n".join([f"{i+1}. {t}" for i, t in enumerate(sample_texts) if t])
    
    analysis_prompt = f"""Analyze this video transcript sample and identify:

SAMPLE TEXT:
{sample}

Provide a brief analysis (2-3 sentences):
1. Content type (comedy, educational, documentary, narrative, etc.)
2. Tone and style (formal, casual, humorous, serious, satirical, etc.)
3. Any special characteristics (wordplay, cultural references, technical terms, etc.)

Keep it concise:"""

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "You are a content analyst. Provide brief, accurate analysis."},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=0.3,
            max_tokens=200
        )
        
        analysis = response.choices[0].message.content.strip()
        print(f"\nğŸ“Š å†…å®¹åˆ†æ:\n{analysis}\n")
        
        return {
            "analysis": analysis,
            "sample_size": len(sample_texts)
        }
    
    except Exception as e:
        print(f"âš ï¸ åˆ†æå¤±è´¥: {e}")
        return {
            "analysis": "General video content requiring natural translation.",
            "sample_size": 0
        }

# ===== ç¬¬äºŒæ­¥ï¼šå®Œæ•´ç¿»è¯‘å…¨æ–‡ =====
def translate_full_script(sentences: list, style_info: dict) -> list:
    """
    ä¸€æ¬¡æ€§ç¿»è¯‘æ•´ä¸ªè„šæœ¬ï¼Œä¿è¯è¿è´¯æ€§
    """
    print("\n" + "="*80)
    print(f"ğŸ“ ç¿»è¯‘å…¨æ–‡ ({SOURCE_LANG} â†’ {TARGET_LANG})")
    print("="*80)
    
    # æ„å»ºå®Œæ•´è„šæœ¬
    full_script = []
    for i, s in enumerate(sentences):
        text = s.get("text", "").strip()
        if text:
            full_script.append(f"{i+1}. {text}")
    
    script_text = "\n".join(full_script)
    style_context = style_info.get("analysis", "")
    
    prompt = f"""You are translating a video transcript from {SOURCE_LANG} to {TARGET_LANG}.

CONTENT ANALYSIS:
{style_context}

FULL TRANSCRIPT:
{script_text}

TRANSLATION REQUIREMENTS:
1. Translate naturally and fluently - as if the video was originally made in {TARGET_LANG}
2. Preserve the original tone, style, and emotional impact
3. Maintain coherence and natural flow between sentences
4. Adapt cultural references and idioms appropriately for {TARGET_LANG} audiences
5. Keep humor, wordplay, and rhetorical devices when present
6. Each sentence should connect logically to the previous and next ones

OUTPUT FORMAT:
Return ONLY the translated lines, numbered exactly as the input:
1. [translation]
2. [translation]
3. [translation]
...

Begin translation:"""

    try:
        print("\nğŸ¤– æ­£åœ¨ç¿»è¯‘...")
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": f"You are a professional translator specializing in video content. Translate from {SOURCE_LANG} to {TARGET_LANG} naturally and accurately."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,  # å¹³è¡¡å‡†ç¡®æ€§å’Œè‡ªç„¶åº¦
            max_tokens=1500
        )
        
        translation = response.choices[0].message.content.strip()
        
        # è§£æç¿»è¯‘ç»“æœ
        lines = []
        for line in translation.split('\n'):
            line = line.strip()
            if not line:
                continue
            # ç§»é™¤åºå·ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼š1. 1) 1ã€ï¼‰
            line = re.sub(r'^\d+[\.\)ã€]\s*', '', line)
            line = clean_text(line)
            if line and len(line) > 1:
                lines.append(line)
        
        print(f"âœ… æˆåŠŸç¿»è¯‘ {len(lines)} / {len(full_script)} å¥\n")
        
        # æ˜¾ç¤ºç¿»è¯‘é¢„è§ˆ
        print("ç¿»è¯‘é¢„è§ˆ:")
        print("-" * 80)
        for i in range(min(5, len(lines))):
            print(f"{i+1}. {lines[i]}")
        if len(lines) > 5:
            print(f"... (è¿˜æœ‰ {len(lines)-5} å¥)")
        print("-" * 80)
        
        return lines
    
    except Exception as e:
        print(f"âŒ å…¨æ–‡ç¿»è¯‘å¤±è´¥: {e}")
        return []

# ===== ç¬¬ä¸‰æ­¥ï¼šè°ƒæ•´å•å¥é•¿åº¦ =====
def adjust_sentence_length(translation: str, target_words: int, context: str) -> str:
    """
    è°ƒæ•´å¥å­é•¿åº¦ä»¥åŒ¹é…éŸ³é¢‘æ—¶é•¿
    """
    current_words = len(translation.split())
    
    # å®¹å·®èŒƒå›´ï¼šÂ±2è¯
    if abs(current_words - target_words) <= 2:
        return translation
    
    # åˆ¤æ–­éœ€è¦ç¼©çŸ­è¿˜æ˜¯æ‰©å±•
    if current_words > target_words + 2:
        action = "shorten"
        instruction = f"Make this sentence more concise while keeping the same meaning and style."
    else:
        action = "expand"
        instruction = f"Expand this sentence naturally with relevant details, maintaining the same style."
    
    prompt = f"""{instruction}

Original ({current_words} words): {translation}
Target length: approximately {target_words} words
Content context: {context}

Output only the adjusted sentence:"""
    
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": f"You are an editor. Adjust sentence length while preserving meaning and style."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=150
        )
        
        adjusted = clean_text(response.choices[0].message.content.strip())
        adjusted_words = len(adjusted.split())
        
        # éªŒè¯è°ƒæ•´æ˜¯å¦æœ‰æ•ˆ
        if adjusted and abs(adjusted_words - target_words) < abs(current_words - target_words):
            return adjusted
        
        return translation
    
    except Exception as e:
        return translation

# ===== ç¬¬å››æ­¥ï¼šåŒ¹é…æ—¶é—´æˆ³å’Œå¾®è°ƒ =====
def match_timestamps_and_adjust(sentences: list, translations: list, style_info: dict) -> tuple:
    """
    å°†ç¿»è¯‘åŒ¹é…åˆ°æ—¶é—´æˆ³ï¼Œå¹¶æ ¹æ®éŸ³é¢‘æ—¶é•¿è°ƒæ•´
    """
    print("\n" + "="*80)
    print("â±ï¸  åŒ¹é…æ—¶é—´æˆ³å¹¶ä¼˜åŒ–é•¿åº¦")
    print("="*80)
    
    results = []
    stats = {
        "total": 0,
        "good_timing": 0,
        "adjusted": 0,
        "failed": 0,
        "too_long": 0,
        "too_short": 0
    }
    
    # ç¡®ä¿æ•°é‡åŒ¹é…
    min_len = min(len(sentences), len(translations))
    
    if len(sentences) != len(translations):
        print(f"âš ï¸  å¥å­æ•°é‡ä¸åŒ¹é…: {len(sentences)} å¥åŸæ–‡ vs {len(translations)} å¥è¯‘æ–‡")
    
    context = style_info.get("analysis", "Video content")
    
    for i in range(min_len):
        sent = sentences[i]
        translation = translations[i] if i < len(translations) else "[TRANSLATION MISSING]"
        
        text_zh = sent.get("text", "").strip()
        start = sent.get("start", 0)
        end = sent.get("end", 0)
        duration = end - start
        
        if not text_zh or duration <= 0:
            continue
        
        stats["total"] += 1
        
        # è®¡ç®—ç›®æ ‡è¯æ•°ï¼ˆè‹±æ–‡çº¦2.5è¯/ç§’ï¼‰
        target_words = max(int(duration * 2.5), 3)
        current_words = len(translation.split())
        
        print(f"\n[{i+1}/{min_len}] æ—¶é•¿ {duration:.2f}s â†’ ç›®æ ‡ {target_words} è¯")
        print(f"  åŸæ–‡: {text_zh}")
        print(f"  è¯‘æ–‡: {translation} ({current_words} è¯)")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´
        word_diff = abs(current_words - target_words)
        
        if word_diff <= 2:
            final_translation = translation
            print(f"  âœ… é•¿åº¦åˆé€‚")
            stats["good_timing"] += 1
        else:
            print(f"  ğŸ”§ è°ƒæ•´é•¿åº¦ ({current_words} â†’ {target_words} è¯)...")
            final_translation = adjust_sentence_length(
                translation, 
                target_words,
                context
            )
            final_words = len(final_translation.split())
            
            if final_translation != translation:
                print(f"  âœ… å·²è°ƒæ•´: {final_translation} ({final_words} è¯)")
                stats["adjusted"] += 1
            else:
                print(f"  âš ï¸  è°ƒæ•´å¤±è´¥ï¼Œä¿æŒåŸæ ·")
            
            time.sleep(0.4)  # é˜²æ­¢APIé™æµ
        
        # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
        word_count = len(final_translation.split())
        est_duration = word_count / 2.5
        duration_ratio = est_duration / duration if duration > 0 else 1.0
        
        # ç»Ÿè®¡æ—¶é•¿åŒ¹é…æƒ…å†µ
        if duration_ratio > 1.2:
            stats["too_long"] += 1
        elif duration_ratio < 0.8:
            stats["too_short"] += 1
        
        results.append({
            "start": start,
            "end": end,
            "duration": round(duration, 2),
            "text_zh": text_zh,
            "text_en": final_translation,
            "word_count": word_count,
            "estimated_duration": round(est_duration, 2),
            "duration_ratio": round(duration_ratio, 2)
        })
    
    print(f"\nâœ… å®Œæˆ: {stats['good_timing']} å¥åˆé€‚, {stats['adjusted']} å¥å·²è°ƒæ•´")
    return results, stats

# ===== ä¸»æµç¨‹ =====
def main():
    print("="*80)
    print("ğŸ¬ é€šç”¨è§†é¢‘ç¿»è¯‘å·¥å…·")
    print(f"   {SOURCE_LANG} â†’ {TARGET_LANG}")
    print("="*80)
    
    # è¯»å–æ•°æ®
    try:
        with open(INPUT_JSON, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {INPUT_JSON}")
        return
    except json.JSONDecodeError:
        print(f"âŒ JSON æ ¼å¼é”™è¯¯")
        return
    
    result = data[0]
    sentences = result.get("sentence_info", [])
    
    if not sentences:
        print("âŒ æœªæ‰¾åˆ°å¥å­ä¿¡æ¯")
        return
    
    print(f"\nâœ… åŠ è½½ {len(sentences)} ä¸ªå¥å­")
    print(f"ğŸ¤– æ¨¡å‹: {MODEL_NAME}")
    
    # æ­¥éª¤1: åˆ†æå†…å®¹é£æ ¼
    style_info = analyze_content_style(sentences)
    
    # æ­¥éª¤2: æ•´ä½“ç¿»è¯‘
    translations = translate_full_script(sentences, style_info)
    
    if not translations:
        print("âŒ ç¿»è¯‘å¤±è´¥ï¼Œç»ˆæ­¢")
        return
    
    # æ­¥éª¤3: åŒ¹é…æ—¶é—´æˆ³å¹¶è°ƒæ•´
    translated, stats = match_timestamps_and_adjust(sentences, translations, style_info)
    
    # ä¿å­˜ç»“æœ
    output = [{
        "key": result.get("key", "unknown"),
        "sentence_info": translated,
        "metadata": {
            "source_language": SOURCE_LANG,
            "target_language": TARGET_LANG,
            "total_sentences": stats["total"],
            "successful": stats["total"] - stats["failed"],
            "failed": stats["failed"],
            "good_timing": stats["good_timing"],
            "adjusted": stats["adjusted"],
            "too_long": stats["too_long"],
            "too_short": stats["too_short"],
            "model": MODEL_NAME,
            "method": "full_script_context_aware"
        }
    }]
    
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*80)
    print("ğŸ“Š ç¿»è¯‘å®Œæˆç»Ÿè®¡")
    print("="*80)
    print(f"æ€»å¥æ•°: {stats['total']}")
    print(f"æˆåŠŸ: {stats['total'] - stats['failed']}")
    print(f"å¤±è´¥: {stats['failed']}")
    print(f"\næ—¶é•¿åŒ¹é…:")
    print(f"  âœ… åˆé€‚ (0.8-1.2x): {stats['good_timing']} ({stats['good_timing']/stats['total']*100:.1f}%)")
    print(f"  ğŸ”§ å·²è°ƒæ•´: {stats['adjusted']} ({stats['adjusted']/stats['total']*100:.1f}%)")
    print(f"  âš ï¸  åé•¿ (>1.2x): {stats['too_long']} ({stats['too_long']/stats['total']*100:.1f}%)")
    print(f"  âš ï¸  åçŸ­ (<0.8x): {stats['too_short']} ({stats['too_short']/stats['total']*100:.1f}%)")
    
    # åˆ—å‡ºéœ€è¦äººå·¥æ£€æŸ¥çš„å¥å­
    problematic = [
        s for s in translated 
        if s["duration_ratio"] > 1.3 or s["duration_ratio"] < 0.7
    ]
    
    if problematic:
        print(f"\nâš ï¸  å»ºè®®äººå·¥æ£€æŸ¥ ({len(problematic)} å¥):")
        for s in problematic[:5]:
            ratio_str = f"{s['duration_ratio']:.2f}x"
            issue = "å¤ªé•¿" if s['duration_ratio'] > 1.3 else "å¤ªçŸ­"
            print(f"\n  [{s['start']:.1f}s] {issue} ({ratio_str})")
            print(f"    åŸæ–‡: {s['text_zh']}")
            print(f"    è¯‘æ–‡: {s['text_en']}")
        
        if len(problematic) > 5:
            print(f"\n  ... è¿˜æœ‰ {len(problematic)-5} å¥éœ€è¦æ£€æŸ¥")
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {OUTPUT_JSON}")
    print("="*80)

if __name__ == "__main__":
    main()