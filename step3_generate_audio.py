import json
import os
import base64
import subprocess
from openai import OpenAI
from pathlib import Path
import wave
import struct
import time

# ===== é…ç½® =====
API_BASE = "https://hackathon.boson.ai/v1"
API_KEY = os.getenv("BOSON_API_KEY", "bai-C8daJQcbo2sMbwgr9aTNmCZM4C1zliRyWLPNA3cRGGksCagH")

INPUT_JSON = "translated_with_timestamps.json"
ORIGINAL_AUDIO = "sleep.mp3"
OUTPUT_DIR = "generated_audio"
FINAL_OUTPUT = "final_english_audio.wav"

SAMPLE_RATE = 24000
CHANNELS = 1
SAMPLE_WIDTH = 2

client = OpenAI(api_key=API_KEY, base_url=API_BASE)

def ensure_dir(path):
    Path(path).mkdir(parents=True, exist_ok=True)

def b64_encode(file_path):
    with open(file_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def get_audio_duration(audio_path):
    """è·å–éŸ³é¢‘æ—¶é•¿"""
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration",
             "-of", "default=noprint_wrappers=1:nokey=1", audio_path],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )
        return float(result.stdout.strip())
    except:
        return 0.0

def extract_audio_segment(input_file, output_file, start_time, duration=None):
    """ä»éŸ³é¢‘ä¸­æå–ç‰‡æ®µ"""
    try:
        cmd = ["ffmpeg", "-y", "-i", input_file, "-ss", str(start_time)]
        if duration:
            cmd.extend(["-t", str(duration)])
        cmd.extend(["-acodec", "copy", output_file])
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except:
        return False

def extract_reference_audio(original_audio, start, duration, output_path):
    """ä»åŸè§†é¢‘æå–å‚è€ƒéŸ³é¢‘"""
    try:
        cmd = [
            "ffmpeg", "-y",
            "-i", original_audio,
            "-ss", str(start),
            "-t", str(duration),
            "-ar", str(SAMPLE_RATE),
            "-ac", str(CHANNELS),
            output_path
        ]
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except:
        return False

def find_best_reference(sentences, min_duration=3.0, max_duration=6.0):
    """æ‰¾åˆ°æœ€é€‚åˆåšå‚è€ƒçš„å¥å­"""
    candidates = []
    
    for i, sent in enumerate(sentences):
        duration = sent.get("duration", 0)
        text = sent.get("text_zh", "")
        
        if min_duration <= duration <= max_duration and len(text) > 8:
            candidates.append((i, sent, duration))
    
    if not candidates:
        candidates = sorted(
            [(i, s, s.get("duration", 0)) for i, s in enumerate(sentences)],
            key=lambda x: x[2],
            reverse=True
        )[:3]
    
    if candidates:
        return candidates[0]
    return None

def generate_with_voice_cloning(text_en, reference_audio, reference_text, output_raw, max_retries=2):
    """
    ä½¿ç”¨è¯­éŸ³å…‹éš†ç”ŸæˆéŸ³é¢‘
    æ·»åŠ é‡è¯•æœºåˆ¶å¤„ç†å¼‚å¸¸é•¿éŸ³é¢‘
    """
    for attempt in range(max_retries):
        try:
            ref_b64 = b64_encode(reference_audio)
            
            response = client.chat.completions.create(
                model="higgs-audio-generation-Hackathon",
                messages=[
                    {"role": "user", "content": reference_text},
                    {
                        "role": "assistant",
                        "content": [{
                            "type": "input_audio",
                            "input_audio": {
                                "data": ref_b64,
                                "format": "wav"
                            }
                        }]
                    },
                    {"role": "user", "content": text_en}
                ],
                modalities=["text", "audio"],
                max_completion_tokens=4096,
                temperature=0.85,
                top_p=0.9,
                stream=False,
                stop=["<|eot_id|>", "<|end_of_text|>", "<|audio_eos|>"],
                extra_body={"top_k": 40}
            )
            
            if hasattr(response.choices[0].message, 'audio') and response.choices[0].message.audio:
                audio_b64 = response.choices[0].message.audio.data
                audio_data = base64.b64decode(audio_b64)
                
                with open(output_raw, "wb") as f:
                    f.write(audio_data)
                
                # æ£€æŸ¥éŸ³é¢‘æ—¶é•¿æ˜¯å¦å¼‚å¸¸
                duration = get_audio_duration(output_raw)
                
                # å¦‚æœéŸ³é¢‘è¶…è¿‡30ç§’ï¼Œå¾ˆå¯èƒ½æ˜¯å¹»è§‰
                if duration > 30:
                    if attempt < max_retries - 1:
                        print(f"  âš ï¸  å¼‚å¸¸é•¿éŸ³é¢‘({duration:.1f}s)ï¼Œé‡è¯• {attempt + 1}/{max_retries - 1}...")
                        time.sleep(1)
                        continue
                    else:
                        print(f"  âš ï¸  å¤šæ¬¡å¼‚å¸¸ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨å¤„ç†")
                
                return True
            
            return False
            
        except Exception as e:
            if attempt < max_retries - 1:
                print(f"  âš ï¸  ç”Ÿæˆå¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries - 1}...")
                time.sleep(1)
            else:
                print(f"  âŒ {str(e)[:80]}")
                return False
    
    return False

def check_and_process_audio(raw_audio, output_audio, reference_duration, target_duration):
    """æ£€æŸ¥å¹¶å¤„ç†ç”Ÿæˆçš„éŸ³é¢‘ï¼ŒåŒ…æ‹¬å¼‚å¸¸æ£€æµ‹"""
    try:
        total_duration = get_audio_duration(raw_audio)
        
        if total_duration == 0:
            return False
        
        # å¼‚å¸¸æ£€æµ‹ï¼šå¦‚æœéŸ³é¢‘è¶…è¿‡é¢„æœŸå¤ªå¤šï¼Œå°è¯•åªä¿ç•™å¼€å¤´éƒ¨åˆ†
        if total_duration > target_duration * 10:  # è¶…è¿‡10å€
            print(f"  ğŸš¨ å¼‚å¸¸é•¿éŸ³é¢‘({total_duration:.1f}s)ï¼Œæˆªå–å‰{target_duration*1.5:.1f}ç§’...")
            
            # åªä¿ç•™å‰é¢åˆç†é•¿åº¦çš„éƒ¨åˆ†
            max_duration = target_duration * 1.5
            if extract_audio_segment(raw_audio, output_audio, 0, max_duration):
                extracted_duration = get_audio_duration(output_audio)
                print(f"  âœ‚ï¸  æˆªå–å: {extracted_duration:.1f}s")
                return True
            else:
                return False
        
        # åˆ¤æ–­æ˜¯å¦åŒ…å«å‚è€ƒéŸ³é¢‘
        contains_reference = total_duration > (reference_duration + target_duration * 0.5)
        
        if contains_reference:
            print(f"  ğŸ“ é•¿éŸ³é¢‘({total_duration:.1f}s)ï¼Œæå–æœ‰æ•ˆéƒ¨åˆ†...")
            start_time = max(reference_duration - 0.3, 0)
            
            if extract_audio_segment(raw_audio, output_audio, start_time):
                extracted_duration = get_audio_duration(output_audio)
                
                # å¦‚æœæå–åè¿˜æ˜¯å¤ªé•¿ï¼Œå†æ¬¡æˆªæ–­
                if extracted_duration > target_duration * 3:
                    print(f"  âš ï¸  æå–åä»ç„¶å¤ªé•¿({extracted_duration:.1f}s)ï¼Œç»§ç»­æˆªå–...")
                    temp_file = output_audio.replace(".wav", "_temp.wav")
                    os.rename(output_audio, temp_file)
                    
                    if extract_audio_segment(temp_file, output_audio, 0, target_duration * 1.5):
                        os.remove(temp_file)
                        extracted_duration = get_audio_duration(output_audio)
                        print(f"  âœ‚ï¸  æœ€ç»ˆ: {extracted_duration:.1f}s")
                    else:
                        os.rename(temp_file, output_audio)
                
                return True
            else:
                return False
        else:
            print(f"  âœ… æ­£å¸¸({total_duration:.1f}s)ï¼Œç›´æ¥ä½¿ç”¨")
            import shutil
            shutil.copy(raw_audio, output_audio)
            return True
        
    except Exception as e:
        print(f"  âš ï¸ {e}")
        return False

def create_silence(duration_seconds, output_path):
    """åˆ›å»ºæŒ‡å®šæ—¶é•¿çš„é™éŸ³WAVæ–‡ä»¶"""
    try:
        # è®¡ç®—æ ·æœ¬æ•°
        num_samples = int(duration_seconds * SAMPLE_RATE)
        
        # åˆ›å»ºé™éŸ³æ•°æ®ï¼ˆå…¨0ï¼‰
        silence_data = b'\x00\x00' * num_samples  # 16-bit samples
        
        # å†™å…¥WAVæ–‡ä»¶
        with wave.open(output_path, 'wb') as wav:
            wav.setnchannels(CHANNELS)
            wav.setsampwidth(SAMPLE_WIDTH)
            wav.setframerate(SAMPLE_RATE)
            wav.writeframes(silence_data)
        
        return True
    except Exception as e:
        print(f"  âš ï¸ åˆ›å»ºé™éŸ³å¤±è´¥: {e}")
        return False

def assemble_audio_timeline(audio_segments, total_duration, output_path):
    """
    æŒ‰æ—¶é—´è½´ç»„è£…éŸ³é¢‘
    
    å‚æ•°:
        audio_segments: [(start_time, audio_file), ...]
        total_duration: æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
        output_path: è¾“å‡ºæ–‡ä»¶
    """
    print("\nğŸ¬ æŒ‰æ—¶é—´è½´ç»„è£…éŸ³é¢‘...")
    print(f"   æ€»æ—¶é•¿: {total_duration:.1f}ç§’")
    print(f"   ç‰‡æ®µæ•°: {len(audio_segments)}")
    
    try:
        # æŒ‰å¼€å§‹æ—¶é—´æ’åº
        audio_segments = sorted(audio_segments, key=lambda x: x[0])
        
        # åˆ›å»ºå®Œæ•´çš„éŸ³é¢‘æ•°æ®
        total_samples = int(total_duration * SAMPLE_RATE)
        
        # åˆå§‹åŒ–ä¸ºé™éŸ³
        print("  ğŸ“ åˆ›å»ºæ—¶é—´è½´...")
        audio_data = bytearray(b'\x00\x00' * total_samples)
        
        # æ’å…¥æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µ
        for i, (start_time, audio_file) in enumerate(audio_segments, 1):
            if not os.path.exists(audio_file):
                print(f"  âš ï¸  è·³è¿‡: {audio_file} (ä¸å­˜åœ¨)")
                continue
            
            try:
                # è¯»å–éŸ³é¢‘ç‰‡æ®µ
                with wave.open(audio_file, 'rb') as wav:
                    if wav.getnchannels() != CHANNELS or wav.getframerate() != SAMPLE_RATE:
                        print(f"  âš ï¸  è·³è¿‡: {audio_file} (æ ¼å¼ä¸åŒ¹é…)")
                        continue
                    
                    frames = wav.readframes(wav.getnframes())
                
                # è®¡ç®—æ’å…¥ä½ç½®
                start_sample = int(start_time * SAMPLE_RATE)
                start_byte = start_sample * SAMPLE_WIDTH
                
                # æ’å…¥æ•°æ®
                end_byte = start_byte + len(frames)
                
                if end_byte > len(audio_data):
                    # æˆªæ–­è¶…å‡ºéƒ¨åˆ†
                    frames = frames[:len(audio_data) - start_byte]
                    end_byte = len(audio_data)
                
                audio_data[start_byte:end_byte] = frames
                
                duration = len(frames) / (SAMPLE_RATE * SAMPLE_WIDTH)
                print(f"  [{i}/{len(audio_segments)}] {start_time:.1f}s: {os.path.basename(audio_file)} ({duration:.1f}s)")
                
            except Exception as e:
                print(f"  âš ï¸  å¤„ç†å¤±è´¥: {audio_file} - {e}")
                continue
        
        # å†™å…¥æœ€ç»ˆæ–‡ä»¶
        print(f"  ğŸ’¾ å†™å…¥æ–‡ä»¶...")
        with wave.open(output_path, 'wb') as wav:
            wav.setnchannels(CHANNELS)
            wav.setsampwidth(SAMPLE_WIDTH)
            wav.setframerate(SAMPLE_RATE)
            wav.writeframes(bytes(audio_data))
        
        print(f"  âœ… ç»„è£…å®Œæˆ: {output_path}")
        return True
        
    except Exception as e:
        print(f"  âŒ ç»„è£…å¤±è´¥: {e}")
        return False

def add_background_music(speech, music, output, volume=0.15):
    """æ·»åŠ èƒŒæ™¯éŸ³ä¹"""
    try:
        cmd = [
            "ffmpeg", "-y",
            "-i", speech,
            "-i", music,
            "-filter_complex",
            f"[1:a]volume={volume}[m];[0:a][m]amix=inputs=2:duration=first",
            output
        ]
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except:
        return False

def extract_background_music(original_audio, output):
    """ä»åŸéŸ³é¢‘æå–èƒŒæ™¯éŸ³ä¹"""
    try:
        cmd = [
            "ffmpeg", "-y",
            "-i", original_audio,
            "-af", "highpass=f=200,lowpass=f=3000,volume=0.3",
            output
        ]
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except:
        return False

def main():
    print("="*80)
    print("ğŸ¤ Step 3: è‹±æ–‡éŸ³é¢‘ç”Ÿæˆï¼ˆæ—¶é—´è½´ç²¾ç¡®å¯¹é½ï¼‰")
    print("="*80)
    
    ensure_dir(OUTPUT_DIR)
    
    # è¯»å–ç¿»è¯‘
    try:
        with open(INPUT_JSON, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except:
        print(f"âŒ æ‰¾ä¸åˆ°: {INPUT_JSON}")
        return
    
    sentences = data[0].get("sentence_info", [])
    print(f"\nâœ… åŠ è½½ {len(sentences)} ä¸ªå¥å­")
    
    # æ£€æŸ¥åŸéŸ³é¢‘
    if not os.path.exists(ORIGINAL_AUDIO):
        print(f"âŒ æ‰¾ä¸åˆ°åŸéŸ³é¢‘: {ORIGINAL_AUDIO}")
        return
    
    print(f"âœ… åŸéŸ³é¢‘: {ORIGINAL_AUDIO}")
    
    # è®¡ç®—æ€»æ—¶é•¿
    if sentences:
        last_sentence = sentences[-1]
        total_duration = last_sentence.get("end", 0)
        print(f"âœ… æ€»æ—¶é•¿: {total_duration:.1f}ç§’\n")
    else:
        print("âŒ æ²¡æœ‰å¥å­æ•°æ®")
        return
    
    # æ­¥éª¤1: æå–å‚è€ƒéŸ³é¢‘
    print("="*80)
    print("ğŸ¯ æ­¥éª¤ 1/3: æå–å‚è€ƒéŸ³è‰²")
    print("="*80)
    
    result = find_best_reference(sentences)
    
    if not result:
        print("âŒ æ— æ³•æ‰¾åˆ°åˆé€‚çš„å‚è€ƒå¥å­")
        return
    
    ref_idx, ref_sent, ref_duration = result
    ref_text = ref_sent.get("text_zh", "")
    ref_start = ref_sent.get("start", 0)
    
    print(f"\né€‰æ‹©å¥å­ {ref_idx+1}:")
    print(f"  æ–‡æœ¬: {ref_text}")
    print(f"  æ—¶é•¿: {ref_duration:.2f}ç§’")
    print(f"  ä½ç½®: {ref_start:.1f}s")
    
    reference_audio = os.path.join(OUTPUT_DIR, "reference.wav")
    
    if not extract_reference_audio(ORIGINAL_AUDIO, ref_start, ref_duration, reference_audio):
        print("âŒ æå–å‚è€ƒéŸ³é¢‘å¤±è´¥")
        return
    
    print(f"  âœ… å‚è€ƒéŸ³é¢‘: {reference_audio}")
    
    # æ­¥éª¤2: æ‰¹é‡ç”Ÿæˆ
    print("\n" + "="*80)
    print("ğŸ¤ æ­¥éª¤ 2/3: ç”Ÿæˆæ‰€æœ‰è‹±æ–‡å¥å­")
    print("="*80)
    print(f"\nğŸ’¡ ä½¿ç”¨å…‹éš†éŸ³è‰²ç”Ÿæˆï¼Œæ—¶é•¿ä¸åŸè§†é¢‘ä¸€è‡´\n")
    
    audio_segments = []  # [(start_time, audio_file), ...]
    stats = {"success": 0, "failed": 0}
    
    for i, sent in enumerate(sentences, 1):
        text_en = sent.get("text_en", "")
        text_zh = sent.get("text_zh", "")
        start_time = sent.get("start", 0)
        target_duration = sent.get("duration", 0)
        
        if not text_en or "[FAILED:" in text_en:
            print(f"[{i:02d}/{len(sentences)}] â­ï¸  è·³è¿‡")
            continue
        
        display = text_en if len(text_en) <= 45 else text_en[:42] + "..."
        print(f"[{i:02d}/{len(sentences)}] {display}")
        print(f"  â±ï¸  {start_time:.1f}s, ç›®æ ‡æ—¶é•¿: {target_duration:.1f}s")
        
        # ç”ŸæˆéŸ³é¢‘
        raw_output = os.path.join(OUTPUT_DIR, f"raw_{i:03d}.wav")
        
        if generate_with_voice_cloning(text_en, reference_audio, ref_text, raw_output, max_retries=3):
            raw_duration = get_audio_duration(raw_output)
            print(f"  ğŸµ ç”Ÿæˆ: {raw_duration:.1f}s")
            
            final_output = os.path.join(OUTPUT_DIR, f"s_{i:03d}.wav")
            
            if check_and_process_audio(raw_output, final_output, ref_duration, target_duration):
                final_duration = get_audio_duration(final_output)
                ratio = final_duration / target_duration if target_duration > 0 else 1.0
                
                # å†æ¬¡æ£€æŸ¥ï¼šå¦‚æœè¿˜æ˜¯å¤ªé•¿ï¼Œæ ‡è®°ä¸ºå¤±è´¥
                if final_duration > target_duration * 5:
                    print(f"  âŒ å¼‚å¸¸ï¼š{final_duration:.1f}sï¼Œè·³è¿‡æ­¤å¥")
                    stats["failed"] += 1
                    if os.path.exists(raw_output):
                        os.remove(raw_output)
                    if os.path.exists(final_output):
                        os.remove(final_output)
                    continue
                
                if 0.7 <= ratio <= 1.3:
                    status = "âœ…"
                elif ratio > 1.3:
                    status = "âš ï¸ åé•¿"
                else:
                    status = "âš ï¸ åçŸ­"
                
                print(f"  {status} æœ€ç»ˆ: {final_duration:.1f}s (æ¯”ä¾‹: {ratio:.2f}x)")
                
                # æ·»åŠ åˆ°æ—¶é—´è½´
                audio_segments.append((start_time, final_output))
                stats["success"] += 1
                
                # æ¸…ç†
                if os.path.exists(raw_output) and raw_output != final_output:
                    os.remove(raw_output)
            else:
                print(f"  âŒ å¤„ç†å¤±è´¥")
                stats["failed"] += 1
        else:
            stats["failed"] += 1
        
        # APIé™æµ
        if i < len(sentences):
            time.sleep(0.5)
    
    print("\n" + "-"*80)
    print(f"ğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
    print(f"   æˆåŠŸ: {stats['success']}/{len(sentences)}")
    print(f"   å¤±è´¥: {stats['failed']}")
    print("-"*80)
    
    if not audio_segments:
        print("\nâŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•éŸ³é¢‘")
        return
    
    # æ­¥éª¤3: æŒ‰æ—¶é—´è½´ç»„è£…
    print("\n" + "="*80)
    print("ğŸ¬ æ­¥éª¤ 3/3: æŒ‰æ—¶é—´è½´ç»„è£…éŸ³é¢‘")
    print("="*80)
    
    speech_only = os.path.join(OUTPUT_DIR, "speech_only.wav")
    
    if assemble_audio_timeline(audio_segments, total_duration, speech_only):
        print(f"\nâœ… è¯­éŸ³è½¨é“å®Œæˆ")
        
        # èƒŒæ™¯éŸ³ä¹
        print("\n" + "="*80)
        add_bgm = input("\næ·»åŠ èƒŒæ™¯éŸ³ä¹? (y/n) [y]: ").strip().lower() or "y"
        
        if add_bgm == "y":
            bgm = os.path.join(OUTPUT_DIR, "bgm.wav")
            
            print("\nğŸµ æå–èƒŒæ™¯éŸ³ä¹...")
            if extract_background_music(ORIGINAL_AUDIO, bgm):
                print("  âœ… æå–å®Œæˆ")
                
                volume = input("èƒŒæ™¯éŸ³ä¹éŸ³é‡ (0.0-1.0) [é»˜è®¤: 0.15]: ").strip()
                volume = float(volume) if volume else 0.15
                
                print(f"ğŸµ æ··åˆéŸ³é¢‘ (éŸ³é‡: {volume})...")
                if add_background_music(speech_only, bgm, FINAL_OUTPUT, volume):
                    print("  âœ… å®Œæˆ")
                else:
                    print("  âš ï¸  æ··åˆå¤±è´¥ï¼Œä½¿ç”¨çº¯è¯­éŸ³")
                    import shutil
                    shutil.copy(speech_only, FINAL_OUTPUT)
            else:
                print("  âš ï¸  æå–å¤±è´¥ï¼Œä½¿ç”¨çº¯è¯­éŸ³")
                import shutil
                shutil.copy(speech_only, FINAL_OUTPUT)
        else:
            import shutil
            shutil.copy(speech_only, FINAL_OUTPUT)
        
        # å®Œæˆ
        print("\n" + "="*80)
        print("âœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼")
        print("="*80)
        
        if os.path.exists(FINAL_OUTPUT):
            size = os.path.getsize(FINAL_OUTPUT) / (1024*1024)
            duration = get_audio_duration(FINAL_OUTPUT)
            
            print(f"\nğŸ“ {FINAL_OUTPUT}")
            print(f"ğŸ“¦ {size:.2f} MB")
            print(f"â±ï¸  {duration:.1f}ç§’")
            
            # æ—¶é•¿å¯¹æ¯”
            original_duration = get_audio_duration(ORIGINAL_AUDIO)
            if original_duration > 0:
                ratio = duration / original_duration
                print(f"ğŸ“Š æ—¶é•¿åŒ¹é…: {ratio:.1%} (åŸè§†é¢‘: {original_duration:.1f}s)")
            
            print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥: python step4_merge_video.py")
        
        print("="*80)
    else:
        print("\nâŒ ç»„è£…å¤±è´¥")

if __name__ == "__main__":
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except:
        print("âŒ éœ€è¦ ffmpeg")
        exit(1)
    
    main()