import json
import os
import subprocess
from openai import OpenAI
from pathlib import Path
import wave
import time

# ===== é…ç½® =====
API_BASE = "https://hackathon.boson.ai/v1"
API_KEY = os.getenv("BOSON_API_KEY", "bai-C8daJQcbo2sMbwgr9aTNmCZM4C1zliRyWLPNA3cRGGksCagH")

INPUT_JSON = "translated_with_timestamps.json"
OUTPUT_DIR = "generated_audio"
FINAL_OUTPUT = "final_english_audio.wav"

SAMPLE_RATE = 24000
CHANNELS = 1
SAMPLE_WIDTH = 2

client = OpenAI(api_key=API_KEY, base_url=API_BASE)

def ensure_dir(path):
    Path(path).mkdir(parents=True, exist_ok=True)

def save_pcm_as_wav(pcm_data, output_path):
    """å°†PCMä¿å­˜ä¸ºWAV"""
    with wave.open(output_path, 'wb') as wav:
        wav.setnchannels(CHANNELS)
        wav.setsampwidth(SAMPLE_WIDTH)
        wav.setframerate(SAMPLE_RATE)
        wav.writeframes(pcm_data)

def generate_audio_simple(text, voice, output_path):
    """
    ä½¿ç”¨ç®€å•APIç”ŸæˆéŸ³é¢‘
    è¿™æ˜¯æ­£ç¡®çš„æ–¹æ³•ï¼
    """
    try:
        response = client.audio.speech.create(
            model="higgs-audio-generation-Hackathon",
            voice=voice,
            input=text,
            response_format="pcm"
        )
        save_pcm_as_wav(response.content, output_path)
        return True
    except Exception as e:
        print(f"  âŒ {str(e)[:80]}")
        return False

def get_audio_duration(audio_path):
    """è·å–éŸ³é¢‘æ—¶é•¿"""
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration",
             "-of", "default=noprint_wrappers=1:nokey=1", audio_path],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )
        return float(result.stdout.strip())
    except:
        return 0.0

def adjust_audio_speed(input_file, output_file, target_duration):
    """
    è°ƒæ•´éŸ³é¢‘é€Ÿåº¦ä»¥åŒ¹é…ç›®æ ‡æ—¶é•¿
    """
    try:
        current_duration = get_audio_duration(input_file)
        if current_duration == 0:
            return False
        
        # è®¡ç®—é€Ÿåº¦è°ƒæ•´æ¯”ä¾‹
        speed_ratio = current_duration / target_duration
        
        # é™åˆ¶è°ƒæ•´èŒƒå›´ï¼ˆ0.8-1.5å€é€Ÿï¼‰
        if speed_ratio < 0.5:
            speed_ratio = 0.5
        elif speed_ratio > 2.0:
            speed_ratio = 2.0
        
        # ä½¿ç”¨atempoè°ƒæ•´é€Ÿåº¦
        cmd = [
            "ffmpeg", "-y",
            "-i", input_file,
            "-filter:a", f"atempo={speed_ratio}",
            output_file
        ]
        
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except:
        return False

def concatenate_audio_files(audio_files, output_path):
    """æ‹¼æ¥éŸ³é¢‘æ–‡ä»¶"""
    if not audio_files:
        return False
    
    print(f"  æ‹¼æ¥ {len(audio_files)} ä¸ªæ–‡ä»¶...")
    
    try:
        # ä½¿ç”¨filter_complex
        inputs = []
        filters = []
        
        for i, audio_path in enumerate(audio_files):
            inputs.extend(["-i", audio_path])
            filters.append(f"[{i}:a]")
        
        filter_str = f"{''.join(filters)}concat=n={len(audio_files)}:v=0:a=1[out]"
        
        cmd = ["ffmpeg", "-y"] + inputs + [
            "-filter_complex", filter_str,
            "-map", "[out]",
            "-ar", str(SAMPLE_RATE),
            "-ac", str(CHANNELS),
            output_path
        ]
        
        subprocess.run(cmd, check=True, capture_output=True)
        return True
        
    except:
        # å¤‡ç”¨ï¼šæ‰‹åŠ¨æ‹¼æ¥
        try:
            with wave.open(output_path, 'wb') as out:
                out.setnchannels(CHANNELS)
                out.setsampwidth(SAMPLE_WIDTH)
                out.setframerate(SAMPLE_RATE)
                
                for audio_file in audio_files:
                    with wave.open(audio_file, 'rb') as inp:
                        out.writeframes(inp.readframes(inp.getnframes()))
            return True
        except Exception as e:
            print(f"  âŒ æ‹¼æ¥å¤±è´¥: {e}")
            return False

def add_background_music(speech, music, output, volume=0.15):
    """æ·»åŠ èƒŒæ™¯éŸ³ä¹"""
    try:
        cmd = [
            "ffmpeg", "-y",
            "-i", speech,
            "-i", music,
            "-filter_complex",
            f"[1:a]volume={volume}[m];[0:a][m]amix=inputs=2:duration=first",
            output
        ]
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except:
        return False

def main():
    print("="*80)
    print("ğŸ¤ Step 3: éŸ³é¢‘ç”Ÿæˆï¼ˆç®€åŒ–ç‰ˆ - åªç”¨é¢„è®¾éŸ³è‰²ï¼‰")
    print("="*80)
    
    ensure_dir(OUTPUT_DIR)
    
    # è¯»å–ç¿»è¯‘
    try:
        with open(INPUT_JSON, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except:
        print(f"âŒ æ‰¾ä¸åˆ°: {INPUT_JSON}")
        return
    
    sentences = data[0].get("sentence_info", [])
    print(f"\nâœ… åŠ è½½ {len(sentences)} ä¸ªå¥å­\n")
    
    # å¯ç”¨éŸ³è‰²
    voices = {
        "1": ("en_woman", "å¥³å£°ï¼ˆæ¸…æ™°ï¼‰"),
        "2": ("en_man", "ç”·å£°ï¼ˆæ²‰ç¨³ï¼‰"),
        "3": ("belinda", "Belindaï¼ˆå¹´è½»å¥³æ€§ï¼‰"),
        "4": ("chadwick", "Chadwickï¼ˆæˆç†Ÿç”·æ€§ï¼‰"),
        "5": ("mabel", "Mabelï¼ˆæ´»æ³¼å¥³æ€§ï¼‰"),
        "6": ("vex", "Vexï¼ˆä¸­æ€§ï¼‰")
    }
    
    print("å¯ç”¨éŸ³è‰²:")
    for k, (name, desc) in voices.items():
        print(f"  {k}. {desc}")
    
    choice = input("\né€‰æ‹©éŸ³è‰² (1-6) [é»˜è®¤: 1]: ").strip() or "1"
    voice = voices.get(choice, ("en_woman", ""))[0]
    
    print(f"\nğŸ¤ ä½¿ç”¨éŸ³è‰²: {voice}")
    print(f"ğŸ”„ å¼€å§‹ç”Ÿæˆ...\n")
    
    generated_files = []
    stats = {"success": 0, "failed": 0, "adjusted": 0}
    
    for i, sent in enumerate(sentences, 1):
        text_en = sent.get("text_en", "")
        target_duration = sent.get("duration", 0)
        
        if not text_en or "[FAILED:" in text_en:
            print(f"[{i:02d}/{len(sentences)}] â­ï¸  è·³è¿‡å¤±è´¥å¥å­")
            continue
        
        # æ˜¾ç¤ºè¿›åº¦
        display_text = text_en if len(text_en) <= 50 else text_en[:47] + "..."
        print(f"[{i:02d}/{len(sentences)}] {display_text}")
        
        output_file = os.path.join(OUTPUT_DIR, f"s_{i:03d}.wav")
        
        # ç”ŸæˆéŸ³é¢‘
        if generate_audio_simple(text_en, voice, output_file):
            actual_duration = get_audio_duration(output_file)
            
            # æ£€æŸ¥æ—¶é•¿
            if actual_duration > 0:
                ratio = actual_duration / target_duration if target_duration > 0 else 1.0
                
                # å¦‚æœæ—¶é•¿å·®è·å¤ªå¤§ï¼Œè°ƒæ•´é€Ÿåº¦
                if ratio > 1.5 or ratio < 0.7:
                    print(f"  âš ï¸  {actual_duration:.1f}s (é¢„æœŸ {target_duration:.1f}s) - è°ƒæ•´ä¸­...")
                    
                    adjusted_file = output_file.replace(".wav", "_adj.wav")
                    if adjust_audio_speed(output_file, adjusted_file, target_duration):
                        os.replace(adjusted_file, output_file)
                        actual_duration = get_audio_duration(output_file)
                        print(f"  âœ… å·²è°ƒæ•´åˆ° {actual_duration:.1f}s")
                        stats["adjusted"] += 1
                    else:
                        print(f"  âš ï¸  è°ƒæ•´å¤±è´¥ï¼Œä¿æŒåŸæ ·")
                
                generated_files.append(output_file)
                stats["success"] += 1
                print(f"  âœ… {actual_duration:.1f}s")
            else:
                print(f"  âŒ éŸ³é¢‘æ— æ•ˆ")
                stats["failed"] += 1
        else:
            stats["failed"] += 1
        
        # é˜²æ­¢APIé™æµ
        if i < len(sentences):
            time.sleep(0.4)
    
    # ç»Ÿè®¡
    print("\n" + "-"*80)
    print(f"ğŸ“Š ç”Ÿæˆå®Œæˆ: {stats['success']}/{len(sentences)} æˆåŠŸ")
    if stats["adjusted"] > 0:
        print(f"   è°ƒé€Ÿ: {stats['adjusted']} ä¸ª")
    if stats["failed"] > 0:
        print(f"   å¤±è´¥: {stats['failed']} ä¸ª")
    print("-"*80)
    
    if not generated_files:
        print("\nâŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•éŸ³é¢‘")
        return
    
    # æ‹¼æ¥
    print("\nğŸ”— æ‹¼æ¥éŸ³é¢‘...")
    speech_only = os.path.join(OUTPUT_DIR, "speech_only.wav")
    
    if concatenate_audio_files(generated_files, speech_only):
        print(f"  âœ… æ‹¼æ¥æˆåŠŸ")
        
        # èƒŒæ™¯éŸ³ä¹ï¼ˆå¯é€‰ï¼‰
        add_bgm = input("\næ·»åŠ èƒŒæ™¯éŸ³ä¹? (y/n) [n]: ").strip().lower()
        
        if add_bgm == "y":
            music_file = input("èƒŒæ™¯éŸ³ä¹æ–‡ä»¶è·¯å¾„: ").strip()
            
            if os.path.exists(music_file):
                print("ğŸµ æ··åˆèƒŒæ™¯éŸ³ä¹...")
                if add_background_music(speech_only, music_file, FINAL_OUTPUT, volume=0.15):
                    print("  âœ… å®Œæˆ")
                else:
                    print("  âš ï¸  å¤±è´¥ï¼Œä½¿ç”¨çº¯è¯­éŸ³ç‰ˆæœ¬")
                    import shutil
                    shutil.copy(speech_only, FINAL_OUTPUT)
            else:
                print("  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                import shutil
                shutil.copy(speech_only, FINAL_OUTPUT)
        else:
            import shutil
            shutil.copy(speech_only, FINAL_OUTPUT)
        
        # å®Œæˆ
        print("\n" + "="*80)
        print("âœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼")
        print("="*80)
        
        if os.path.exists(FINAL_OUTPUT):
            size_mb = os.path.getsize(FINAL_OUTPUT) / (1024*1024)
            duration = get_audio_duration(FINAL_OUTPUT)
            
            print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶: {FINAL_OUTPUT}")
            print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {size_mb:.2f} MB")
            print(f"â±ï¸  éŸ³é¢‘æ—¶é•¿: {duration:.1f} ç§’")
            print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥: python step4_merge_video.py")
        
        print("="*80)
    else:
        print("\nâŒ æ‹¼æ¥å¤±è´¥")

if __name__ == "__main__":
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except:
        print("âŒ éœ€è¦å®‰è£… ffmpeg")
        exit(1)
    
    main()