"""
TTSéŸ³é¢‘ç”Ÿæˆæ¨¡å—ï¼ˆå¢å¼ºç‰ˆï¼‰
åŠŸèƒ½ï¼š
1. è¯­éŸ³å…‹éš†ï¼ˆä½¿ç”¨åŸè§†é¢‘éŸ³è‰²ï¼‰
2. é¢„è®¾å£°éŸ³ï¼ˆå¥³å£°ã€ç”·å£°ç­‰ï¼‰
3. äººå£°èƒŒæ™¯åˆ†ç¦»
4. æ—¶é•¿ç²¾ç¡®å¯¹é½
"""

import os
import json
import base64
import subprocess
from openai import OpenAI
from pathlib import Path
import wave
import time
import tempfile
import shutil
import numpy as np


class TTSGenerator:
    """æ–‡å­—è½¬è¯­éŸ³ç”Ÿæˆå™¨ - å¢å¼ºç‰ˆ"""
    
    # é¢„è®¾å£°éŸ³é…ç½®
    PRESET_VOICES = {
        "female_american": {
            "name": "ç¾å¼å¥³å£°ï¼ˆæ¸…æ™°æ¸©æš–ï¼‰",
            "system_prompt": (
                "You are an English text-to-speech (TTS) model. "
                "Always use the same clear, warm female American English voice. "
                "Speak naturally, fluently, and consistently across all generations. "
                "Do not include any background noise, effects, or non-speech sounds."
            ),
            "temperature": 0.4
        },
        "female_british": {
            "name": "è‹±å¼å¥³å£°ï¼ˆä¼˜é›…ï¼‰",
            "system_prompt": (
                "You are an English text-to-speech model. "
                "Use a clear, elegant female British English voice with RP accent. "
                "Speak naturally and fluently. "
                "No background noise or effects."
            ),
            "temperature": 0.4
        },
        "male_american": {
            "name": "ç¾å¼ç”·å£°ï¼ˆæ²‰ç¨³ï¼‰",
            "system_prompt": (
                "You are an English text-to-speech model. "
                "Use a deep, steady male American English voice. "
                "Speak clearly and professionally. "
                "No background noise or effects."
            ),
            "temperature": 0.4
        },
        "male_british": {
            "name": "è‹±å¼ç”·å£°ï¼ˆç£æ€§ï¼‰",
            "system_prompt": (
                "You are an English text-to-speech model. "
                "Use a deep, smooth male British English voice. "
                "Speak with clarity and warmth. "
                "No background noise or effects."
            ),
            "temperature": 0.4
        }
    }
    
    def __init__(self, api_key=None, api_base=None):
        """
        åˆå§‹åŒ–TTSç”Ÿæˆå™¨
        
        Args:
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
        """
        self.api_key = api_key or os.getenv("BOSON_API_KEY", "bai-C8daJQcbo2sMbwgr9aTNmCZM4C1zliRyWLPNA3cRGGksCagH")
        self.api_base = api_base or "https://hackathon.boson.ai/v1"
        self.model = "higgs-audio-generation-Hackathon"
        
        self.SAMPLE_RATE = 24000
        self.CHANNELS = 1
        self.SAMPLE_WIDTH = 2
        
        self.client = None
    
    def _init_client(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        if self.client is not None:
            return
        
        print(f"ğŸ”„ åˆå§‹åŒ– Boson AI TTS å®¢æˆ·ç«¯...")
        self.client = OpenAI(api_key=self.api_key, base_url=self.api_base)
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    def generate(self, translated_json_path, output_audio_path, target_lang="en", 
                 bitrate="192k", original_audio_path=None, 
                 voice_mode="clone", preset_voice="female_american",
                 separate_vocals=False, keep_background=True, bgm_volume=0.18):
        """
        ä»ç¿»è¯‘çš„JSONç”Ÿæˆå®Œæ•´éŸ³é¢‘
        
        Args:
            translated_json_path: ç¿»è¯‘åçš„JSONæ–‡ä»¶è·¯å¾„
            output_audio_path: è¾“å‡ºéŸ³é¢‘è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            bitrate: éŸ³é¢‘æ¯”ç‰¹ç‡
            original_audio_path: åŸå§‹éŸ³é¢‘è·¯å¾„ï¼ˆç”¨äºè¯­éŸ³å…‹éš†æˆ–èƒŒæ™¯éŸ³æå–ï¼‰
            voice_mode: å£°éŸ³æ¨¡å¼ ("clone" å…‹éš†åŸéŸ³ / "preset" ä½¿ç”¨é¢„è®¾å£°éŸ³)
            preset_voice: é¢„è®¾å£°éŸ³ç±»å‹ï¼ˆå½“voice_mode="preset"æ—¶ä½¿ç”¨ï¼‰
            separate_vocals: æ˜¯å¦åˆ†ç¦»äººå£°å’ŒèƒŒæ™¯éŸ³
            keep_background: æ˜¯å¦ä¿ç•™èƒŒæ™¯éŸ³
            bgm_volume: èƒŒæ™¯éŸ³éŸ³é‡ (0.0-1.0)
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(translated_json_path):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {translated_json_path}")
            return False
        
        try:
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            self._init_client()
            
            # è¯»å–ç¿»è¯‘æ•°æ®
            with open(translated_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            sentences = data[0].get("sentence_info", [])
            total = len(sentences)
            
            print("=" * 80)
            print(f"ğŸ”Š å¼€å§‹ç”Ÿæˆ {total} ä¸ªéŸ³é¢‘ç‰‡æ®µ...")
            print(f"ğŸ¤ å£°éŸ³æ¨¡å¼: {voice_mode}")
            if voice_mode == "preset":
                print(f"ğŸµ é¢„è®¾å£°éŸ³: {self.PRESET_VOICES[preset_voice]['name']}")
            print("=" * 80)
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = Path(output_audio_path).parent / "temp_audio"
            temp_dir.mkdir(exist_ok=True)
            
            # æ­¥éª¤1: å¤„ç†åŸå§‹éŸ³é¢‘ï¼ˆåˆ†ç¦»äººå£°/æå–å‚è€ƒï¼‰
            reference_audio = None
            reference_text = None
            bgm_path = None
            
            if original_audio_path and os.path.exists(original_audio_path):
                if voice_mode == "clone":
                    # å…‹éš†æ¨¡å¼ï¼šæå–å‚è€ƒéŸ³é¢‘
                    print("\nğŸ¯ æ­¥éª¤ 1: æå–å‚è€ƒéŸ³è‰²ï¼ˆå…‹éš†æ¨¡å¼ï¼‰")
                    print("-" * 80)
                    
                    if separate_vocals:
                        # å…ˆåˆ†ç¦»äººå£°
                        print("ğŸ§ åˆ†ç¦»äººå£°å’ŒèƒŒæ™¯éŸ³...")
                        vocals_path, bgm_path = self._separate_audio(
                            original_audio_path, 
                            str(temp_dir)
                        )
                        if vocals_path:
                            print(f"âœ… äººå£°è½¨: {vocals_path}")
                            source_for_reference = vocals_path
                        else:
                            print("âš ï¸  äººå£°åˆ†ç¦»å¤±è´¥ï¼Œä½¿ç”¨åŸéŸ³é¢‘")
                            source_for_reference = original_audio_path
                    else:
                        source_for_reference = original_audio_path
                    
                    # ä»äººå£°è½¨ï¼ˆæˆ–åŸéŸ³é¢‘ï¼‰æå–å‚è€ƒç‰‡æ®µ
                    ref_result = self._find_best_reference(sentences)
                    if ref_result:
                        ref_idx, ref_sent, ref_duration = ref_result
                        ref_text = ref_sent.get("text", "")
                        ref_start = ref_sent.get("start", 0)
                        
                        reference_audio = str(temp_dir / "reference.wav")
                        
                        if self._extract_reference_audio(source_for_reference, ref_start, ref_duration, reference_audio):
                            reference_text = ref_text
                            print(f"âœ… ä½¿ç”¨å‚è€ƒå¥å­ {ref_idx+1}: {ref_text[:30]}...")
                        else:
                            reference_audio = None
                
                elif separate_vocals and keep_background:
                    # é¢„è®¾å£°éŸ³æ¨¡å¼ä½†éœ€è¦ä¿ç•™èƒŒæ™¯éŸ³
                    print("\nğŸ§ æ­¥éª¤ 1: æå–èƒŒæ™¯éŸ³")
                    print("-" * 80)
                    _, bgm_path = self._separate_audio(original_audio_path, str(temp_dir))
                    if bgm_path:
                        print(f"âœ… èƒŒæ™¯éŸ³: {bgm_path}")
            
            # æ­¥éª¤2: ç”Ÿæˆæ¯ä¸ªå¥å­çš„éŸ³é¢‘
            print("\nğŸ¤ æ­¥éª¤ 2: ç”ŸæˆéŸ³é¢‘ç‰‡æ®µ")
            print("-" * 80)
            
            audio_segments = []
            success_count = 0
            
            for i, sentence in enumerate(sentences, 1):
                # è·å–ç¿»è¯‘æ–‡æœ¬
                if target_lang == "en":
                    text = sentence.get("text_en", "")
                else:
                    text = sentence.get("text_translated", "")
                
                start_time = sentence.get("start", 0)
                end_time = sentence.get("end", 0)
                target_duration = end_time - start_time
                
                if not text or "[FAILED:" in text:
                    print(f"  [{i}/{total}] â­ï¸  è·³è¿‡")
                    continue
                
                display = text if len(text) <= 45 else text[:42] + "..."
                print(f"  [{i}/{total}] {display}")
                
                # ç”ŸæˆéŸ³é¢‘
                raw_output = str(temp_dir / f"raw_{i:03d}.wav")
                final_output = str(temp_dir / f"segment_{i:03d}.wav")
                
                if voice_mode == "clone" and reference_audio and reference_text:
                    # ä½¿ç”¨è¯­éŸ³å…‹éš†
                    if self._generate_with_voice_cloning(text, reference_audio, reference_text, raw_output):
                        raw_duration = self._get_audio_duration(raw_output)
                        print(f"    ğŸµ ç”Ÿæˆ: {raw_duration:.1f}s")
                        
                        # è°ƒæ•´æ—¶é•¿
                        if self._align_audio_duration(raw_output, target_duration, final_output):
                            audio_segments.append((start_time, final_output))
                            success_count += 1
                        else:
                            print(f"    âš ï¸  æ—¶é•¿è°ƒæ•´å¤±è´¥")
                    else:
                        print(f"    âŒ ç”Ÿæˆå¤±è´¥")
                
                elif voice_mode == "preset":
                    # ä½¿ç”¨é¢„è®¾å£°éŸ³
                    if self._generate_with_preset_voice(text, preset_voice, raw_output):
                        raw_duration = self._get_audio_duration(raw_output)
                        print(f"    ğŸµ ç”Ÿæˆ: {raw_duration:.1f}s")
                        
                        # è°ƒæ•´æ—¶é•¿
                        if self._align_audio_duration(raw_output, target_duration, final_output):
                            audio_segments.append((start_time, final_output))
                            success_count += 1
                        else:
                            print(f"    âš ï¸  æ—¶é•¿è°ƒæ•´å¤±è´¥")
                    else:
                        print(f"    âŒ ç”Ÿæˆå¤±è´¥")
                else:
                    # åˆ›å»ºé™éŸ³ï¼ˆé™çº§å¤„ç†ï¼‰
                    if self._create_silence(target_duration, final_output):
                        audio_segments.append((start_time, final_output))
                
                # é¿å…APIé™æµ
                if i < total:
                    time.sleep(0.3)
            
            print(f"\nâœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {success_count}/{total}")
            
            # æ­¥éª¤3: è®¡ç®—æ€»æ—¶é•¿
            if sentences:
                total_duration = sentences[-1].get("end", 0)
            else:
                total_duration = 60
            
            # æ­¥éª¤4: æŒ‰æ—¶é—´è½´ç»„è£…éŸ³é¢‘
            print("\nğŸ”„ æ­¥éª¤ 3: æŒ‰æ—¶é—´è½´ç»„è£…éŸ³é¢‘")
            print("-" * 80)
            
            speech_only = str(temp_dir / "speech_only.wav")
            
            if self._assemble_audio_timeline(audio_segments, total_duration, speech_only):
                print(f"âœ… è¯­éŸ³è½¨é“å®Œæˆ: {speech_only}")
                
                # æ­¥éª¤5: æ··åˆèƒŒæ™¯éŸ³ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if keep_background and bgm_path and os.path.exists(bgm_path):
                    print("\nğŸµ æ­¥éª¤ 4: æ··åˆèƒŒæ™¯éŸ³")
                    print("-" * 80)
                    
                    temp_output = str(temp_dir / "with_bgm.wav")
                    if self._mix_audio_with_bgm(speech_only, bgm_path, temp_output, bgm_volume):
                        speech_only = temp_output
                        print(f"âœ… èƒŒæ™¯éŸ³æ··åˆå®Œæˆ")
                
                # è½¬æ¢ä¸ºMP3æ ¼å¼
                print("\nğŸ”„ æ­¥éª¤ 5: è½¬æ¢ä¸ºMP3")
                print("-" * 80)
                self._convert_to_mp3(speech_only, output_audio_path, bitrate)
                
                print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {output_audio_path}")
                print("=" * 80)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                shutil.rmtree(temp_dir)
                
                return True
            else:
                print("âŒ éŸ³é¢‘ç»„è£…å¤±è´¥")
                return False
        
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _separate_audio(self, input_audio, output_dir):
        """
        ä½¿ç”¨ Demucs åˆ†ç¦»äººå£°å’ŒèƒŒæ™¯éŸ³
        
        Returns:
            tuple: (vocals_path, bgm_path)
        """
        try:
            # æ£€æŸ¥ demucs æ˜¯å¦å®‰è£…
            subprocess.run(
                ["demucs", "--help"], 
                stdout=subprocess.DEVNULL, 
                stderr=subprocess.DEVNULL,
                check=True
            )
        except:
            print("âš ï¸  Demucs æœªå®‰è£…ï¼Œè·³è¿‡äººå£°åˆ†ç¦»")
            print("   æç¤º: pip install demucs")
            return None, None
        
        try:
            audio_name = Path(input_audio).stem
            
            # æ‰§è¡Œåˆ†ç¦»
            subprocess.run(
                ["demucs", "-n", "htdemucs", "--two-stems=vocals", input_audio],
                check=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            
            # æ„å»ºè¾“å‡ºè·¯å¾„
            separated_root = Path("separated") / "htdemucs" / audio_name
            vocals = separated_root / "vocals.wav"
            bgm = separated_root / "no_vocals.wav"
            
            # å¤åˆ¶åˆ°ç»Ÿä¸€è¾“å‡ºç›®å½•
            final_vocals = Path(output_dir) / "vocals.wav"
            final_bgm = Path(output_dir) / "accompaniment.wav"
            
            if vocals.exists():
                shutil.copy(vocals, final_vocals)
            else:
                final_vocals = None
            
            if bgm.exists():
                shutil.copy(bgm, final_bgm)
            else:
                final_bgm = None
            
            return str(final_vocals) if final_vocals else None, str(final_bgm) if final_bgm else None
        
        except Exception as e:
            print(f"âš ï¸  äººå£°åˆ†ç¦»å¤±è´¥: {e}")
            return None, None
    
    def _generate_with_preset_voice(self, text, voice_type, output_path, max_retries=10):
        """ä½¿ç”¨é¢„è®¾å£°éŸ³ç”ŸæˆéŸ³é¢‘"""
        if not text.strip():
            return False
        
        voice_config = self.PRESET_VOICES.get(voice_type, self.PRESET_VOICES["female_american"])
        
        for attempt in range(max_retries):
            try:
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": voice_config["system_prompt"]
                        },
                        {"role": "user", "content": text.strip()}
                    ],
                    modalities=["text", "audio"],
                    max_completion_tokens=2048,
                    temperature=voice_config["temperature"],
                    top_p=0.9,
                    stream=False,
                    timeout=30  # æ·»åŠ 30ç§’è¶…æ—¶
                )
                
                # è®¡ç®—ç”Ÿæˆæ—¶é—´
                generation_time = time.time() - start_time
                
                audio_b64 = getattr(response.choices[0].message.audio, "data", None)
                if not audio_b64:
                    if attempt < max_retries - 1:
                        print(f"    âš ï¸  æ— éŸ³é¢‘å“åº”ï¼Œ{attempt+1}/{max_retries} æ¬¡é‡è¯•...")
                        time.sleep(3)
                        continue
                    return False
                
                tmp_output = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
                with open(tmp_output, "wb") as f:
                    f.write(base64.b64decode(audio_b64))
                
                duration = self._get_audio_duration(tmp_output)
                
                # æ£€æŸ¥ç”Ÿæˆæ˜¯å¦å¼‚å¸¸
                # 1. éŸ³é¢‘æ—¶é•¿å¼‚å¸¸ï¼ˆå¤ªé•¿æˆ–å¤ªçŸ­ï¼‰
                if duration > 20 or duration < 0.5:
                    os.remove(tmp_output)
                    if attempt < max_retries - 1:
                        print(f"    âš ï¸  å¼‚å¸¸æ—¶é•¿ {duration:.1f}sï¼Œé‡æ–°ç”Ÿæˆ...")
                        time.sleep(3)
                        continue
                    return False
                
                # 2. ç”Ÿæˆæ—¶é—´å¼‚å¸¸ï¼ˆè¶…è¿‡30ç§’ï¼‰
                if generation_time > 30:
                    print(f"    âš ï¸  ç”Ÿæˆæ—¶é—´è¿‡é•¿ ({generation_time:.1f}s)ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
                    # ä½†å¦‚æœéŸ³é¢‘çœ‹èµ·æ¥æ­£å¸¸ï¼Œè¿˜æ˜¯ä½¿ç”¨å®ƒ
                    if duration < 1 or duration > 15:
                        os.remove(tmp_output)
                        if attempt < max_retries - 1:
                            print(f"    âš ï¸  é‡æ–°ç”Ÿæˆ...")
                            time.sleep(3)
                            continue
                        return False
                
                os.rename(tmp_output, output_path)
                return True
            
            except TimeoutError:
                print(f"    âš ï¸  è¯·æ±‚è¶…æ—¶ï¼Œ{attempt+1}/{max_retries} æ¬¡é‡è¯•...")
                if attempt < max_retries - 1:
                    time.sleep(5)
                else:
                    return False
            
            except Exception as e:
                error_msg = str(e)
                if "timeout" in error_msg.lower() or "timed out" in error_msg.lower():
                    print(f"    âš ï¸  è¶…æ—¶é”™è¯¯ï¼Œ{attempt+1}/{max_retries} æ¬¡é‡è¯•...")
                elif attempt < max_retries - 1:
                    print(f"    âš ï¸  é”™è¯¯: {error_msg[:60]}ï¼Œé‡è¯•ä¸­...")
                else:
                    print(f"    âŒ é”™è¯¯: {error_msg[:60]}")
                    return False
                
                if attempt < max_retries - 1:
                    time.sleep(3)
        
        return False
    
    def _align_audio_duration(self, input_file, target_duration, output_file):
        """è°ƒæ•´éŸ³é¢‘æ—¶é•¿ä»¥ç²¾ç¡®å¯¹é½"""
        try:
            actual_duration = self._get_audio_duration(input_file)
            
            if actual_duration <= 0:
                return False
            
            ratio = target_duration / actual_duration
            
            # å¦‚æœé•¿åº¦æ¥è¿‘ï¼Œç›´æ¥ä½¿ç”¨
            if 0.9 <= ratio <= 1.1:
                shutil.copy(input_file, output_file)
                return True
            
            # éœ€è¦è°ƒé€Ÿ
            if 0.5 < ratio < 2.0:
                speed = 1.0 / ratio
                return self._change_audio_speed(input_file, output_file, speed)
            
            # é•¿åº¦å·®å¼‚å¤ªå¤§ï¼Œè¡¥é™éŸ³æˆ–æˆªæ–­
            if ratio >= 2.0:
                return self._pad_silence(input_file, output_file, target_duration - actual_duration)
            else:
                # æˆªæ–­
                shutil.copy(input_file, output_file)
                return True
        
        except:
            return False
    
    def _change_audio_speed(self, input_file, output_file, speed):
        """æ”¹å˜éŸ³é¢‘æ’­æ”¾é€Ÿåº¦"""
        try:
            subprocess.run(
                ["ffmpeg", "-y", "-i", input_file, "-filter:a", f"atempo={speed}", output_file],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True
            )
            return True
        except:
            return False
    
    def _pad_silence(self, input_file, output_file, pad_seconds):
        """åœ¨éŸ³é¢‘åè¡¥é™éŸ³"""
        try:
            subprocess.run(
                ["ffmpeg", "-y", "-i", input_file, "-af", f"apad=pad_dur={pad_seconds}", output_file],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True
            )
            return True
        except:
            return False
    
    def _mix_audio_with_bgm(self, speech, bgm, output_path, volume=0.2):
        """æ··åˆè¯­éŸ³å’ŒèƒŒæ™¯éŸ³"""
        try:
            subprocess.run(
                [
                    "ffmpeg", "-y",
                    "-i", speech,
                    "-i", bgm,
                    "-filter_complex",
                    f"[1:a]volume={volume}[bgm];[0:a][bgm]amix=inputs=2:duration=first",
                    output_path
                ],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                check=True
            )
            return True
        except:
            return False
    
    def _find_best_reference(self, sentences, min_duration=3.0, max_duration=6.0):
        """æ‰¾åˆ°æœ€é€‚åˆåšå‚è€ƒçš„å¥å­"""
        candidates = []
        
        for i, sent in enumerate(sentences):
            duration = sent.get("end", 0) - sent.get("start", 0)
            text = sent.get("text", "")
            
            if min_duration <= duration <= max_duration and len(text) > 8:
                candidates.append((i, sent, duration))
        
        if not candidates:
            candidates = sorted(
                [(i, s, s.get("end", 0) - s.get("start", 0)) for i, s in enumerate(sentences)],
                key=lambda x: x[2],
                reverse=True
            )[:3]
        
        if candidates:
            return candidates[0]
        return None
    
    def _extract_reference_audio(self, input_audio, start, duration, output_path):
        """ä»åŸè§†é¢‘æå–å‚è€ƒéŸ³é¢‘"""
        try:
            cmd = [
                "ffmpeg", "-y",
                "-i", input_audio,
                "-ss", str(start),
                "-t", str(duration),
                "-ar", str(self.SAMPLE_RATE),
                "-ac", str(self.CHANNELS),
                output_path
            ]
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            return True
        except:
            return False
    
    def _generate_with_voice_cloning(self, text, reference_audio, reference_text, output_path, max_retries=3):
        """ä½¿ç”¨è¯­éŸ³å…‹éš†ç”ŸæˆéŸ³é¢‘"""
        for attempt in range(max_retries):
            try:
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                
                # è¯»å–å‚è€ƒéŸ³é¢‘å¹¶ç¼–ç ä¸ºbase64
                with open(reference_audio, "rb") as f:
                    ref_b64 = base64.b64encode(f.read()).decode("utf-8")
                
                # è°ƒç”¨API
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "user", "content": reference_text},
                        {
                            "role": "assistant",
                            "content": [{
                                "type": "input_audio",
                                "input_audio": {
                                    "data": ref_b64,
                                    "format": "wav"
                                }
                            }]
                        },
                        {"role": "user", "content": text}
                    ],
                    modalities=["text", "audio"],
                    max_completion_tokens=4096,
                    temperature=0.85,
                    top_p=0.9,
                    stream=False,
                    stop=["<|eot_id|>", "<|end_of_text|>", "<|audio_eos|>"],
                    extra_body={"top_k": 40},
                    timeout=45  # æ·»åŠ 45ç§’è¶…æ—¶
                )
                
                # è®¡ç®—ç”Ÿæˆæ—¶é—´
                generation_time = time.time() - start_time
                
                # è·å–ç”Ÿæˆçš„éŸ³é¢‘
                if hasattr(response.choices[0].message, 'audio') and response.choices[0].message.audio:
                    audio_b64 = response.choices[0].message.audio.data
                    audio_data = base64.b64decode(audio_b64)
                    
                    with open(output_path, "wb") as f:
                        f.write(audio_data)
                    
                    # æ£€æŸ¥éŸ³é¢‘æ—¶é•¿æ˜¯å¦å¼‚å¸¸
                    duration = self._get_audio_duration(output_path)
                    
                    # æ£€æŸ¥ç”Ÿæˆæ˜¯å¦å¼‚å¸¸
                    # 1. éŸ³é¢‘æ—¶é•¿å¼‚å¸¸
                    if duration > 30:
                        print(f"    âš ï¸  å¼‚å¸¸æ—¶é•¿ {duration:.1f}s")
                        if attempt < max_retries - 1:
                            print(f"    âš ï¸  é‡æ–°ç”Ÿæˆ...")
                            time.sleep(2)
                            continue
                    
                    # 2. ç”Ÿæˆæ—¶é—´å¼‚å¸¸ï¼ˆè¶…è¿‡45ç§’ï¼‰
                    if generation_time > 45:
                        print(f"    âš ï¸  ç”Ÿæˆæ—¶é—´è¿‡é•¿ ({generation_time:.1f}s)")
                        # ä½†å¦‚æœéŸ³é¢‘çœ‹èµ·æ¥æ­£å¸¸ï¼Œè¿˜æ˜¯ä½¿ç”¨å®ƒ
                        if duration < 1 or duration > 20:
                            if attempt < max_retries - 1:
                                print(f"    âš ï¸  é‡æ–°ç”Ÿæˆ...")
                                time.sleep(2)
                                continue
                    
                    return True
                
                # æ²¡æœ‰éŸ³é¢‘å“åº”
                if attempt < max_retries - 1:
                    print(f"    âš ï¸  æ— éŸ³é¢‘å“åº”ï¼Œ{attempt+1}/{max_retries} æ¬¡é‡è¯•...")
                    time.sleep(2)
                    continue
                
                return False
            
            except TimeoutError:
                print(f"    âš ï¸  å…‹éš†è¶…æ—¶ï¼Œ{attempt+1}/{max_retries} æ¬¡é‡è¯•...")
                if attempt < max_retries - 1:
                    time.sleep(3)
                else:
                    return False
            
            except Exception as e:
                error_msg = str(e)
                if "timeout" in error_msg.lower() or "timed out" in error_msg.lower():
                    print(f"    âš ï¸  è¶…æ—¶é”™è¯¯ï¼Œ{attempt+1}/{max_retries} æ¬¡é‡è¯•...")
                elif attempt < max_retries - 1:
                    print(f"    âš ï¸  é”™è¯¯: {error_msg[:60]}ï¼Œé‡è¯•ä¸­...")
                else:
                    print(f"    âŒ å…‹éš†å¤±è´¥: {error_msg[:60]}")
                    return False
                
                if attempt < max_retries - 1:
                    time.sleep(2)
        
        return False
    
    def _create_silence(self, duration_seconds, output_path):
        """åˆ›å»ºé™éŸ³éŸ³é¢‘"""
        try:
            num_samples = int(duration_seconds * self.SAMPLE_RATE)
            silence_data = b'\x00\x00' * num_samples
            
            with wave.open(output_path, 'wb') as wav:
                wav.setnchannels(self.CHANNELS)
                wav.setsampwidth(self.SAMPLE_WIDTH)
                wav.setframerate(self.SAMPLE_RATE)
                wav.writeframes(silence_data)
            
            return True
        except:
            return False
    
    def _assemble_audio_timeline(self, audio_segments, total_duration, output_path):
        """æŒ‰æ—¶é—´è½´ç»„è£…éŸ³é¢‘"""
        try:
            # æŒ‰å¼€å§‹æ—¶é—´æ’åº
            audio_segments = sorted(audio_segments, key=lambda x: x[0])
            
            # åˆ›å»ºå®Œæ•´çš„éŸ³é¢‘æ•°æ®
            total_samples = int(total_duration * self.SAMPLE_RATE)
            audio_data = bytearray(b'\x00\x00' * total_samples)
            
            # æ’å…¥æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µ
            for i, (start_time, audio_file) in enumerate(audio_segments, 1):
                if not os.path.exists(audio_file):
                    continue
                
                try:
                    with wave.open(audio_file, 'rb') as wav:
                        if wav.getnchannels() != self.CHANNELS or wav.getframerate() != self.SAMPLE_RATE:
                            continue
                        
                        frames = wav.readframes(wav.getnframes())
                    
                    # è®¡ç®—æ’å…¥ä½ç½®
                    start_sample = int(start_time * self.SAMPLE_RATE)
                    start_byte = start_sample * self.SAMPLE_WIDTH
                    end_byte = start_byte + len(frames)
                    
                    if end_byte > len(audio_data):
                        frames = frames[:len(audio_data) - start_byte]
                        end_byte = len(audio_data)
                    
                    audio_data[start_byte:end_byte] = frames
                    
                except:
                    continue
            
            # å†™å…¥æœ€ç»ˆæ–‡ä»¶
            with wave.open(output_path, 'wb') as wav:
                wav.setnchannels(self.CHANNELS)
                wav.setsampwidth(self.SAMPLE_WIDTH)
                wav.setframerate(self.SAMPLE_RATE)
                wav.writeframes(bytes(audio_data))
            
            return True
        
        except:
            return False
    
    def _get_audio_duration(self, audio_path):
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        try:
            result = subprocess.run(
                ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                 "-of", "default=noprint_wrappers=1:nokey=1", audio_path],
                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
            )
            return float(result.stdout.strip())
        except:
            return 0.0
    
    def _convert_to_mp3(self, input_wav, output_mp3, bitrate="192k"):
        """å°†WAVè½¬æ¢ä¸ºMP3"""
        try:
            cmd = [
                "ffmpeg", "-y",
                "-i", input_wav,
                "-acodec", "libmp3lame",
                "-ab", bitrate,
                output_mp3
            ]
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            return True
        except:
            return False