"""
TTSéŸ³é¢‘ç”Ÿæˆæ¨¡å—
ä½¿ç”¨ Boson AI è¯­éŸ³å…‹éš†ç”ŸæˆéŸ³é¢‘
"""

import os
import json
import base64
import subprocess
from openai import OpenAI
from pathlib import Path
import wave
import time


class TTSGenerator:
    """æ–‡å­—è½¬è¯­éŸ³ç”Ÿæˆå™¨ - ä½¿ç”¨ Boson AI è¯­éŸ³å…‹éš†"""
    
    def __init__(self, api_key=None, api_base=None):
        """
        åˆå§‹åŒ–TTSç”Ÿæˆå™¨
        
        Args:
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
        """
        self.api_key = api_key or os.getenv("BOSON_API_KEY", "bai-C8daJQcbo2sMbwgr9aTNmCZM4C1zliRyWLPNA3cRGGksCagH")
        self.api_base = api_base or "https://hackathon.boson.ai/v1"
        self.model = "higgs-audio-generation-Hackathon"
        
        self.SAMPLE_RATE = 24000
        self.CHANNELS = 1
        self.SAMPLE_WIDTH = 2
        
        self.client = None
    
    def _init_client(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        if self.client is not None:
            return
        
        print(f"ğŸ”„ åˆå§‹åŒ– Boson AI TTS å®¢æˆ·ç«¯...")
        self.client = OpenAI(api_key=self.api_key, base_url=self.api_base)
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    def generate(self, translated_json_path, output_audio_path, target_lang="en", bitrate="192k", original_audio_path=None):
        """
        ä»ç¿»è¯‘çš„JSONç”Ÿæˆå®Œæ•´éŸ³é¢‘
        
        Args:
            translated_json_path: ç¿»è¯‘åçš„JSONæ–‡ä»¶è·¯å¾„
            output_audio_path: è¾“å‡ºéŸ³é¢‘è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            bitrate: éŸ³é¢‘æ¯”ç‰¹ç‡
            original_audio_path: åŸå§‹éŸ³é¢‘è·¯å¾„ï¼ˆç”¨äºæå–å‚è€ƒéŸ³è‰²ï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(translated_json_path):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {translated_json_path}")
            return False
        
        try:
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            self._init_client()
            
            # è¯»å–ç¿»è¯‘æ•°æ®
            with open(translated_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            sentences = data[0].get("sentence_info", [])
            total = len(sentences)
            
            print(f"ğŸ”Š å¼€å§‹ç”Ÿæˆ {total} ä¸ªéŸ³é¢‘ç‰‡æ®µ...")
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = Path(output_audio_path).parent / "temp_audio"
            temp_dir.mkdir(exist_ok=True)
            
            # æ­¥éª¤1: æå–å‚è€ƒéŸ³é¢‘
            reference_audio = None
            reference_text = None
            
            if original_audio_path and os.path.exists(original_audio_path):
                print("\nğŸ¯ æå–å‚è€ƒéŸ³è‰²...")
                ref_result = self._find_best_reference(sentences)
                
                if ref_result:
                    ref_idx, ref_sent, ref_duration = ref_result
                    ref_text = ref_sent.get("text", "")
                    ref_start = ref_sent.get("start", 0)
                    
                    reference_audio = str(temp_dir / "reference.wav")
                    
                    if self._extract_reference_audio(original_audio_path, ref_start, ref_duration, reference_audio):
                        reference_text = ref_text
                        print(f"  âœ… ä½¿ç”¨å‚è€ƒå¥å­ {ref_idx+1}: {ref_text[:30]}...")
                    else:
                        reference_audio = None
            
            # æ­¥éª¤2: ç”Ÿæˆæ¯ä¸ªå¥å­çš„éŸ³é¢‘
            audio_segments = []
            success_count = 0
            
            for i, sentence in enumerate(sentences, 1):
                # è·å–ç¿»è¯‘æ–‡æœ¬
                if target_lang == "en":
                    text = sentence.get("text_en", "")
                else:
                    text = sentence.get("text_translated", "")
                
                start_time = sentence.get("start", 0)
                target_duration = sentence.get("end", 0) - start_time
                
                if not text or "[FAILED:" in text:
                    print(f"  [{i}/{total}] â­ï¸  è·³è¿‡")
                    continue
                
                display = text if len(text) <= 45 else text[:42] + "..."
                print(f"  [{i}/{total}] {display}")
                
                # ç”ŸæˆéŸ³é¢‘
                raw_output = str(temp_dir / f"raw_{i:03d}.wav")
                final_output = str(temp_dir / f"segment_{i:03d}.wav")
                
                if reference_audio and reference_text:
                    # ä½¿ç”¨è¯­éŸ³å…‹éš†
                    if self._generate_with_voice_cloning(text, reference_audio, reference_text, raw_output):
                        raw_duration = self._get_audio_duration(raw_output)
                        print(f"    ğŸµ ç”Ÿæˆ: {raw_duration:.1f}s")
                        
                        # å¤„ç†éŸ³é¢‘é•¿åº¦
                        if self._process_audio_length(raw_output, final_output, target_duration):
                            audio_segments.append((start_time, final_output))
                            success_count += 1
                        else:
                            print(f"    âš ï¸  å¤„ç†å¤±è´¥")
                    else:
                        print(f"    âŒ ç”Ÿæˆå¤±è´¥")
                else:
                    # æ²¡æœ‰å‚è€ƒéŸ³é¢‘ï¼Œåˆ›å»ºé™éŸ³
                    if self._create_silence(target_duration, final_output):
                        audio_segments.append((start_time, final_output))
                
                # é¿å…APIé™æµ
                if i < total:
                    time.sleep(0.3)
            
            print(f"\nâœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {success_count}/{total}")
            
            # æ­¥éª¤3: è®¡ç®—æ€»æ—¶é•¿
            if sentences:
                total_duration = sentences[-1].get("end", 0)
            else:
                total_duration = 60
            
            # æ­¥éª¤4: æŒ‰æ—¶é—´è½´ç»„è£…éŸ³é¢‘
            print("\nğŸ”„ æŒ‰æ—¶é—´è½´ç»„è£…éŸ³é¢‘...")
            
            temp_output = str(temp_dir / "assembled.wav")
            
            if self._assemble_audio_timeline(audio_segments, total_duration, temp_output):
                # è½¬æ¢ä¸ºMP3æ ¼å¼
                print("ğŸ”„ è½¬æ¢ä¸ºMP3...")
                self._convert_to_mp3(temp_output, output_audio_path, bitrate)
                
                print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {output_audio_path}")
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                import shutil
                shutil.rmtree(temp_dir)
                
                return True
            else:
                print("âŒ éŸ³é¢‘ç»„è£…å¤±è´¥")
                return False
        
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _find_best_reference(self, sentences, min_duration=3.0, max_duration=6.0):
        """æ‰¾åˆ°æœ€é€‚åˆåšå‚è€ƒçš„å¥å­"""
        candidates = []
        
        for i, sent in enumerate(sentences):
            duration = sent.get("end", 0) - sent.get("start", 0)
            text = sent.get("text", "")
            
            if min_duration <= duration <= max_duration and len(text) > 8:
                candidates.append((i, sent, duration))
        
        if not candidates:
            candidates = sorted(
                [(i, s, s.get("end", 0) - s.get("start", 0)) for i, s in enumerate(sentences)],
                key=lambda x: x[2],
                reverse=True
            )[:3]
        
        if candidates:
            return candidates[0]
        return None
    
    def _extract_reference_audio(self, input_audio, start, duration, output_path):
        """ä»åŸè§†é¢‘æå–å‚è€ƒéŸ³é¢‘"""
        try:
            cmd = [
                "ffmpeg", "-y",
                "-i", input_audio,
                "-ss", str(start),
                "-t", str(duration),
                "-ar", str(self.SAMPLE_RATE),
                "-ac", str(self.CHANNELS),
                output_path
            ]
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            return True
        except:
            return False
    
    def _generate_with_voice_cloning(self, text, reference_audio, reference_text, output_path, max_retries=2):
        """ä½¿ç”¨è¯­éŸ³å…‹éš†ç”ŸæˆéŸ³é¢‘"""
        for attempt in range(max_retries):
            try:
                # è¯»å–å‚è€ƒéŸ³é¢‘å¹¶ç¼–ç ä¸ºbase64
                with open(reference_audio, "rb") as f:
                    ref_b64 = base64.b64encode(f.read()).decode("utf-8")
                
                # è°ƒç”¨API
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "user", "content": reference_text},
                        {
                            "role": "assistant",
                            "content": [{
                                "type": "input_audio",
                                "input_audio": {
                                    "data": ref_b64,
                                    "format": "wav"
                                }
                            }]
                        },
                        {"role": "user", "content": text}
                    ],
                    modalities=["text", "audio"],
                    max_completion_tokens=4096,
                    temperature=0.85,
                    top_p=0.9,
                    stream=False,
                    stop=["<|eot_id|>", "<|end_of_text|>", "<|audio_eos|>"],
                    extra_body={"top_k": 40}
                )
                
                # è·å–ç”Ÿæˆçš„éŸ³é¢‘
                if hasattr(response.choices[0].message, 'audio') and response.choices[0].message.audio:
                    audio_b64 = response.choices[0].message.audio.data
                    audio_data = base64.b64decode(audio_b64)
                    
                    with open(output_path, "wb") as f:
                        f.write(audio_data)
                    
                    # æ£€æŸ¥éŸ³é¢‘æ—¶é•¿æ˜¯å¦å¼‚å¸¸
                    duration = self._get_audio_duration(output_path)
                    
                    if duration > 30:  # å¼‚å¸¸é•¿éŸ³é¢‘
                        if attempt < max_retries - 1:
                            print(f"    âš ï¸  å¼‚å¸¸é•¿éŸ³é¢‘({duration:.1f}s)ï¼Œé‡è¯•...")
                            time.sleep(1)
                            continue
                    
                    return True
                
                return False
            
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"    âš ï¸  ç”Ÿæˆå¤±è´¥ï¼Œé‡è¯•...")
                    time.sleep(1)
                else:
                    print(f"    âŒ {str(e)[:80]}")
                    return False
        
        return False
    
    def _process_audio_length(self, raw_audio, output_audio, target_duration):
        """å¤„ç†ç”Ÿæˆçš„éŸ³é¢‘é•¿åº¦"""
        try:
            duration = self._get_audio_duration(raw_audio)
            
            if duration == 0:
                return False
            
            # å¦‚æœéŸ³é¢‘é•¿åº¦åˆç†ï¼Œç›´æ¥ä½¿ç”¨
            if 0.5 <= duration / target_duration <= 2.0:
                import shutil
                shutil.copy(raw_audio, output_audio)
                return True
            
            # å¦‚æœå¤ªé•¿ï¼Œæˆªå–
            if duration > target_duration * 2:
                cmd = [
                    "ffmpeg", "-y",
                    "-i", raw_audio,
                    "-t", str(target_duration * 1.2),
                    "-acodec", "copy",
                    output_audio
                ]
                subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                return True
            
            # å¦åˆ™ç›´æ¥ä½¿ç”¨
            import shutil
            shutil.copy(raw_audio, output_audio)
            return True
        
        except:
            return False
    
    def _create_silence(self, duration_seconds, output_path):
        """åˆ›å»ºé™éŸ³éŸ³é¢‘"""
        try:
            num_samples = int(duration_seconds * self.SAMPLE_RATE)
            silence_data = b'\x00\x00' * num_samples
            
            with wave.open(output_path, 'wb') as wav:
                wav.setnchannels(self.CHANNELS)
                wav.setsampwidth(self.SAMPLE_WIDTH)
                wav.setframerate(self.SAMPLE_RATE)
                wav.writeframes(silence_data)
            
            return True
        except:
            return False
    
    def _assemble_audio_timeline(self, audio_segments, total_duration, output_path):
        """æŒ‰æ—¶é—´è½´ç»„è£…éŸ³é¢‘"""
        try:
            # æŒ‰å¼€å§‹æ—¶é—´æ’åº
            audio_segments = sorted(audio_segments, key=lambda x: x[0])
            
            # åˆ›å»ºå®Œæ•´çš„éŸ³é¢‘æ•°æ®
            total_samples = int(total_duration * self.SAMPLE_RATE)
            audio_data = bytearray(b'\x00\x00' * total_samples)
            
            # æ’å…¥æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µ
            for i, (start_time, audio_file) in enumerate(audio_segments, 1):
                if not os.path.exists(audio_file):
                    continue
                
                try:
                    with wave.open(audio_file, 'rb') as wav:
                        if wav.getnchannels() != self.CHANNELS or wav.getframerate() != self.SAMPLE_RATE:
                            continue
                        
                        frames = wav.readframes(wav.getnframes())
                    
                    # è®¡ç®—æ’å…¥ä½ç½®
                    start_sample = int(start_time * self.SAMPLE_RATE)
                    start_byte = start_sample * self.SAMPLE_WIDTH
                    end_byte = start_byte + len(frames)
                    
                    if end_byte > len(audio_data):
                        frames = frames[:len(audio_data) - start_byte]
                        end_byte = len(audio_data)
                    
                    audio_data[start_byte:end_byte] = frames
                    
                except:
                    continue
            
            # å†™å…¥æœ€ç»ˆæ–‡ä»¶
            with wave.open(output_path, 'wb') as wav:
                wav.setnchannels(self.CHANNELS)
                wav.setsampwidth(self.SAMPLE_WIDTH)
                wav.setframerate(self.SAMPLE_RATE)
                wav.writeframes(bytes(audio_data))
            
            return True
        
        except:
            return False
    
    def _get_audio_duration(self, audio_path):
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        try:
            result = subprocess.run(
                ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                 "-of", "default=noprint_wrappers=1:nokey=1", audio_path],
                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
            )
            return float(result.stdout.strip())
        except:
            return 0.0
    
    def _convert_to_mp3(self, input_wav, output_mp3, bitrate="192k"):
        """å°†WAVè½¬æ¢ä¸ºMP3"""
        try:
            cmd = [
                "ffmpeg", "-y",
                "-i", input_wav,
                "-acodec", "libmp3lame",
                "-ab", bitrate,
                output_mp3
            ]
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            return True
        except:
            return False