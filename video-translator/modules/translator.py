"""
ç¿»è¯‘æ¨¡å—
ä½¿ç”¨ Boson AI API å°†æ–‡æœ¬ç¿»è¯‘æˆç›®æ ‡è¯­è¨€ï¼ˆå¢å¼ºç‰ˆ - æ”¯æŒé£æ ¼åˆ†æå’Œå¯¹æ¯”è¾“å‡ºï¼‰
"""

import os
import json
import time
import re
from openai import OpenAI


class Translator:
    """æ–‡æœ¬ç¿»è¯‘å™¨ - ä½¿ç”¨ Boson AIï¼ˆå¢å¼ºç‰ˆï¼‰"""
    
    def __init__(self, api_key=None, api_base=None, model=None):
        """
        åˆå§‹åŒ–ç¿»è¯‘å™¨
        
        Args:
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            model: æ¨¡å‹åç§°
        """
        self.api_key = api_key or os.getenv("BOSON_API_KEY", "bai-C8daJQcbo2sMbwgr9aTNmCZM4C1zliRyWLPNA3cRGGksCagH")
        self.api_base = api_base or "https://hackathon.boson.ai/v1"
        self.model = model or "Qwen3-32B-non-thinking-Hackathon"
        self.client = None
    
    def _init_client(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        if self.client is not None:
            return
        
        print(f"ğŸ”„ åˆå§‹åŒ– Boson AI å®¢æˆ·ç«¯...")
        
        try:
            self.client = OpenAI(api_key=self.api_key, base_url=self.api_base)
            print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
        
        except Exception as e:
            print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def translate(self, input_json_path, output_json_path, target_lang="en"):
        """
        ç¿»è¯‘JSONæ–‡ä»¶ä¸­çš„æ‰€æœ‰å¥å­
        
        Args:
            input_json_path: è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
            output_json_path: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(input_json_path):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_json_path}")
            return False
        
        try:
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            self._init_client()
            
            # è¯»å–è¾“å…¥æ–‡ä»¶
            with open(input_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if not isinstance(data, list) or len(data) == 0:
                print("âŒ æ— æ•ˆçš„JSONæ ¼å¼")
                return False
            
            result = data[0]
            sentences = result.get("sentence_info", [])
            total = len(sentences)
            
            print("=" * 80)
            print(f"ğŸ¬ Step 2: æ–‡æœ¬ç¿»è¯‘")
            print("=" * 80)
            print(f"âœ… åŠ è½½ {total} ä¸ªå¥å­")
            
            # è·å–è¯­è¨€åç§°
            source_lang = "Chinese"  # å‡è®¾æºè¯­è¨€æ˜¯ä¸­æ–‡
            target_lang_name = self._get_language_name(target_lang)
            print(f"ğŸŒ ç¿»è¯‘æ–¹å‘: {source_lang} â†’ {target_lang_name}")
            
            # ===== æ­¥éª¤1: åˆ†æå†…å®¹é£æ ¼ =====
            print("\n" + "=" * 80)
            print("ğŸ” æ­¥éª¤ 1/3: åˆ†æè§†é¢‘å†…å®¹é£æ ¼")
            print("=" * 80)
            style_info = self._analyze_content_style(sentences)
            
            # ===== æ­¥éª¤2: æ•´æ®µç¿»è¯‘ =====
            print("\n" + "=" * 80)
            print(f"ğŸ“ æ­¥éª¤ 2/3: æ•´æ®µç¿»è¯‘ ({source_lang} â†’ {target_lang_name})")
            print("=" * 80)
            translations = self._translate_full_script(sentences, style_info, source_lang, target_lang_name)
            
            if not translations:
                print("âŒ ç¿»è¯‘å¤±è´¥")
                return False
            
            # ===== æ­¥éª¤2.5: æ•´ä½“æ¶¦è‰²ï¼ˆå¯é€‰ - é»˜è®¤å…³é—­ï¼‰=====
            # å¦‚æœéœ€è¦æ›´è‡ªç„¶çš„ç¿»è¯‘ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
            # print("\n" + "=" * 80)
            # print("ğŸ­ æ­¥éª¤ 2.5/3: æ•´ä½“æ¶¦è‰²ï¼ˆå¯é€‰ï¼‰")
            # print("=" * 80)
            # translations = self._refine_translation_globally(sentences, translations, style_info, target_lang_name)
            
            # ===== æ­¥éª¤3: è¾“å‡ºç¿»è¯‘å¯¹æ¯” =====
            print("\n" + "=" * 80)
            print("âœï¸  æ­¥éª¤ 3/3: ç¿»è¯‘å¯¹æ¯”")
            print("=" * 80)
            
            # æ˜¾ç¤ºè¯¦ç»†çš„ç¿»è¯‘å¯¹æ¯”
            print("\nç¿»è¯‘å¯¹æ¯”:")
            print("-" * 80)
            for i in range(min(len(sentences), len(translations))):
                orig = sentences[i].get("text", "")
                trans = translations[i]
                orig_words = len(orig)
                trans_words = len(trans.split())
                
                print(f"\n[{i+1}/{total}] åŸæ–‡: {orig}")
                print(f"     è¯‘æ–‡: {trans}")
                print(f"     è¯æ•°: ä¸­æ–‡{orig_words}å­— â†’ è‹±æ–‡{trans_words}è¯")
            
            if len(sentences) > 5:
                print(f"\n... (ä»…æ˜¾ç¤ºå‰5å¥ï¼Œå…±{total}å¥)")
            print("-" * 80)
            
            # æ„å»ºè¾“å‡º
            translated_sentences = []
            for i, s in enumerate(sentences):
                trans_text = translations[i] if i < len(translations) else ""
                
                # æ ¹æ®ç›®æ ‡è¯­è¨€å†³å®šå­—æ®µå
                if target_lang == "en":
                    field_name = "text_en"
                else:
                    field_name = "text_translated"
                
                translated_sentences.append({
                    "text": s.get("text", ""),
                    field_name: trans_text,
                    "start": s.get("start", 0),
                    "end": s.get("end", 0)
                })
            
            # æ›´æ–°æ•°æ®
            data[0]["sentence_info"] = translated_sentences
            
            # ä¿å­˜ç»“æœ
            with open(output_json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ ç¿»è¯‘å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³: {output_json_path}")
            print("=" * 80)
            return True
        
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _analyze_content_style(self, sentences):
        """åˆ†æè§†é¢‘å†…å®¹é£æ ¼"""
        # æŠ½æ ·åˆ†æï¼šå–å‰5å¥å’Œå2å¥
        sample_texts = [s.get("text", "").strip() for s in sentences[:5]]
        sample_texts += [s.get("text", "").strip() for s in sentences[-2:]]
        sample = "\n".join([f"{i+1}. {t}" for i, t in enumerate(sample_texts) if t])
        
        prompt = f"""Analyze this video transcript sample and identify:

SAMPLE TEXT:
{sample}

Provide a brief analysis (2-3 sentences):
1. Content type (e.g. comedy, educational, narrative, etc.)
2. Tone and style (formal, casual, humorous, etc.)
3. Any special traits (wordplay, technical terms, etc.)

Keep it concise:"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a content analyst."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )
            analysis = response.choices[0].message.content.strip()
            print(f"\nğŸ“Š å†…å®¹åˆ†æ:\n{analysis}\n")
            return {"analysis": analysis}
        except Exception as e:
            print(f"âš ï¸ åˆ†æå¤±è´¥: {e}")
            return {"analysis": "General video content."}
    
    def _translate_full_script(self, sentences, style_info, source_lang, target_lang):
        """æ•´æ®µç¿»è¯‘ï¼ˆä¿ç•™æ—¶é—´æˆ³ç»“æ„ï¼‰"""
        # æ„å»ºå®Œæ•´è„šæœ¬
        full_script = []
        for i, s in enumerate(sentences):
            text = s.get("text", "").strip()
            if text:
                full_script.append(f"{i+1}. {text}")
        script_text = "\n".join(full_script)
        
        style_context = style_info.get("analysis", "")
        
        prompt = f"""You are translating a video transcript from {source_lang} to {target_lang}.

CONTENT ANALYSIS:
{style_context}

FULL TRANSCRIPT:
{script_text}

TRANSLATION REQUIREMENTS:
1. Translate naturally and fluently as if it were originally in {target_lang}.
2. Keep the same tone, humor, and emotional style.
3. Output numbered sentences exactly as in the input (1., 2., 3., ...).
4. Only return the translated lines â€” do not repeat the {source_lang} text.

Begin translation:"""
        
        try:
            print("\nğŸ¤– æ­£åœ¨ç¿»è¯‘ä¸­...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a professional translator for video subtitles."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=2000
            )
            
            translation = response.choices[0].message.content.strip()
            lines = []
            for line in translation.split("\n"):
                line = line.strip()
                if not line:
                    continue
                # å»æ‰åºå·ï¼ˆæ”¯æŒ 1. / 1) / 1ã€ç­‰ï¼‰
                line = re.sub(r"^\d+[\.\)ã€]\s*", "", line)
                line = self._clean_text(line)
                if line and len(line) > 1:
                    lines.append(line)
            
            print(f"âœ… æˆåŠŸç¿»è¯‘ {len(lines)} å¥\n")
            
            # æ˜¾ç¤ºç¿»è¯‘é¢„è§ˆ
            print("ç¿»è¯‘é¢„è§ˆ:")
            print("-" * 80)
            for i in range(min(5, len(lines))):
                print(f"{i+1}. {lines[i]}")
            if len(lines) > 5:
                print(f"... (è¿˜æœ‰ {len(lines)-5} å¥)")
            print("-" * 80)
            
            return lines
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
            return []
    
    def _clean_text(self, text):
        """æ¸…ç†ç¿»è¯‘æ–‡æœ¬"""
        # ç§»é™¤ä¸­æ–‡å­—ç¬¦
        text = re.sub(r'[\u4e00-\u9fff]+', '', text)
        # ç§»é™¤ä¸­æ–‡æ ‡ç‚¹
        text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ã€Šã€‹ã€ã€‘ï¼ˆï¼‰]', '', text)
        # æ ‡å‡†åŒ–ç©ºæ ¼
        text = ' '.join(text.split())
        return text.strip()
    
    def _refine_translation_globally(self, sentences, translations, style_info, target_lang):
        """æ•´ä½“æ¶¦è‰²ï¼ˆä¿æŒå¹½é»˜ä¸èŠ‚å¥æ„Ÿï¼‰- å¯é€‰åŠŸèƒ½"""
        print("\nğŸ­ æ­£åœ¨è¿›è¡Œæ•´ä½“æ¶¦è‰²ï¼ˆä¿æŒå¹½é»˜ä¸èŠ‚å¥æ„Ÿï¼‰...")
        
        style_context = style_info.get("analysis", "")
        
        # æ„é€ ä¸­è‹±å¯¹ç…§æ–‡æœ¬
        paired_lines = []
        for i, s in enumerate(sentences):
            orig = s.get("text", "").strip()
            trans = translations[i] if i < len(translations) else ""
            if orig and trans:
                paired_lines.append(f"{i+1}. {orig}\nâ†’ {trans}")
        paired_text = "\n".join(paired_lines)
        
        prompt = f"""
You are a bilingual humor script editor.
Below is a bilingual translation of a video narration.

Your task:
1. Polish the {target_lang} translation as a whole so it reads naturally, witty, and rhythmic.
2. Preserve all jokes, humor, and comedic pacing.
3. Keep the meaning faithful to the original.
4. Keep the numbering (1., 2., 3., ...). One line per number.
5. Do NOT output the original text, only the improved {target_lang}.

CONTENT STYLE:
{style_context}

TRANSLATION DRAFT:
{paired_text}

Now rewrite the {target_lang} lines according to the above requirements.
Output format:
1. ...
2. ...
"""
        
        try:
            print("ğŸ¤– LLM æ­£åœ¨æ•´ä½“æ¶¦è‰²...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"You are a witty, natural-sounding {target_lang} script editor."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2500
            )
            
            refined_text = response.choices[0].message.content.strip()
            refined_lines = []
            for line in refined_text.split("\n"):
                line = line.strip()
                if not line:
                    continue
                # å»æ‰åºå·
                line = re.sub(r"^\d+[\.\)ã€]\s*", "", line)
                line = self._clean_text(line)
                if line:
                    refined_lines.append(line)
            
            print(f"âœ… æˆåŠŸæ•´ä½“ä¼˜åŒ– {len(refined_lines)} å¥")
            print("æ¶¦è‰²é¢„è§ˆ:")
            print("-" * 80)
            for i in range(min(5, len(refined_lines))):
                print(f"{i+1}. {refined_lines[i]}")
            if len(refined_lines) > 5:
                print(f"... (è¿˜æœ‰ {len(refined_lines)-5} å¥)")
            print("-" * 80)
            
            return refined_lines
        
        except Exception as e:
            print(f"âš ï¸ æ•´ä½“æ¶¦è‰²å¤±è´¥: {e}")
            return translations
    
    def _get_language_name(self, lang_code):
        """è·å–è¯­è¨€åç§°"""
        language_names = {
            "en": "English",
            "zh": "Chinese",
            "ja": "Japanese",
            "ko": "Korean",
            "fr": "French",
            "de": "German",
            "es": "Spanish",
            "ru": "Russian",
            "ar": "Arabic",
            "hi": "Hindi"
        }
        return language_names.get(lang_code, "English")