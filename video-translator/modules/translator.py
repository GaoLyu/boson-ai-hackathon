"""
ç¿»è¯‘æ¨¡å—
ä½¿ç”¨ Boson AI API å°†æ–‡æœ¬ç¿»è¯‘æˆç›®æ ‡è¯­è¨€
"""

import os
import json
import time
import re
from openai import OpenAI


class Translator:
    """æ–‡æœ¬ç¿»è¯‘å™¨ - ä½¿ç”¨ Boson AI"""
    
    def __init__(self, api_key=None, api_base=None, model=None):
        """
        åˆå§‹åŒ–ç¿»è¯‘å™¨
        
        Args:
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            model: æ¨¡å‹åç§°
        """
        self.api_key = api_key or os.getenv("BOSON_API_KEY", "bai-C8daJQcbo2sMbwgr9aTNmCZM4C1zliRyWLPNA3cRGGksCagH")
        self.api_base = api_base or "https://hackathon.boson.ai/v1"
        self.model = model or "Qwen3-32B-non-thinking-Hackathon"
        self.client = None
    
    def _init_client(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        if self.client is not None:
            return
        
        print(f"ğŸ”„ åˆå§‹åŒ– Boson AI å®¢æˆ·ç«¯...")
        
        try:
            self.client = OpenAI(api_key=self.api_key, base_url=self.api_base)
            print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
        
        except Exception as e:
            print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def translate(self, input_json_path, output_json_path, target_lang="en"):
        """
        ç¿»è¯‘JSONæ–‡ä»¶ä¸­çš„æ‰€æœ‰å¥å­
        
        Args:
            input_json_path: è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
            output_json_path: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(input_json_path):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_json_path}")
            return False
        
        try:
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            self._init_client()
            
            # è¯»å–è¾“å…¥æ–‡ä»¶
            with open(input_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if not isinstance(data, list) or len(data) == 0:
                print("âŒ æ— æ•ˆçš„JSONæ ¼å¼")
                return False
            
            result = data[0]
            sentences = result.get("sentence_info", [])
            total = len(sentences)
            
            print(f"ğŸŒ å¼€å§‹ç¿»è¯‘ {total} ä¸ªå¥å­...")
            
            # ç¬¬ä¸€æ­¥ï¼šåˆ†æå†…å®¹é£æ ¼
            style_info = self._analyze_content_style(sentences, target_lang)
            
            # ç¬¬äºŒæ­¥ï¼šæ•´æ®µç¿»è¯‘
            translations = self._translate_full_script(sentences, style_info, target_lang)
            
            if not translations:
                print("âŒ ç¿»è¯‘å¤±è´¥")
                return False
            
            # ç¬¬ä¸‰æ­¥ï¼šé•¿åº¦è°ƒæ•´
            adjusted = self._adjust_by_length(sentences, translations, target_lang)
            
            # æ„å»ºè¾“å‡º
            translated_sentences = []
            for i, s in enumerate(sentences):
                trans_text = adjusted[i] if i < len(adjusted) else ""
                translated_sentences.append({
                    "text": s.get("text", ""),
                    "text_en" if target_lang == "en" else "text_translated": trans_text,
                    "start": s.get("start", 0),
                    "end": s.get("end", 0)
                })
            
            # æ›´æ–°æ•°æ®
            data[0]["sentence_info"] = translated_sentences
            
            # ä¿å­˜ç»“æœ
            with open(output_json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ å·²ä¿å­˜: {output_json_path}")
            return True
        
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _analyze_content_style(self, sentences, target_lang):
        """åˆ†æè§†é¢‘å†…å®¹é£æ ¼"""
        print("\nğŸ” åˆ†æå†…å®¹é£æ ¼...")
        
        # æŠ½æ ·åˆ†æ
        sample_texts = [s.get("text", "").strip() for s in sentences[:5]]
        sample_texts += [s.get("text", "").strip() for s in sentences[-2:]]
        sample = "\n".join([f"{i+1}. {t}" for i, t in enumerate(sample_texts) if t])
        
        lang_name = self._get_language_name(target_lang)
        
        prompt = f"""Analyze this video transcript sample and identify:

SAMPLE TEXT:
{sample}

Provide a brief analysis (2-3 sentences):
1. Content type (e.g. comedy, educational, narrative, etc.)
2. Tone and style (formal, casual, humorous, etc.)
3. Any special traits (wordplay, technical terms, etc.)

Keep it concise:"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a content analyst."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )
            analysis = response.choices[0].message.content.strip()
            print(f"ğŸ“Š åˆ†æç»“æœ: {analysis[:100]}...")
            return {"analysis": analysis}
        except Exception as e:
            print(f"âš ï¸ åˆ†æå¤±è´¥: {e}")
            return {"analysis": "General video content."}
    
    def _translate_full_script(self, sentences, style_info, target_lang):
        """æ•´æ®µç¿»è¯‘"""
        print(f"\nğŸ“ æ­£åœ¨ç¿»è¯‘å…¨æ–‡...")
        
        full_script = []
        for i, s in enumerate(sentences):
            text = s.get("text", "").strip()
            if text:
                full_script.append(f"{i+1}. {text}")
        script_text = "\n".join(full_script)
        
        style_context = style_info.get("analysis", "")
        lang_name = self._get_language_name(target_lang)
        
        prompt = f"""You are translating a video transcript to {lang_name}.

CONTENT ANALYSIS:
{style_context}

FULL TRANSCRIPT:
{script_text}

TRANSLATION REQUIREMENTS:
1. Translate naturally and fluently as if it were originally in {lang_name}.
2. Keep the same tone, humor, and emotional style.
3. Output numbered sentences exactly as in the input (1., 2., 3., ...).
4. Only return the translated lines â€” do not repeat the original text.

Begin translation:"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a professional translator for video subtitles."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=2000
            )
            
            translation = response.choices[0].message.content.strip()
            lines = []
            for line in translation.split("\n"):
                line = line.strip()
                if not line:
                    continue
                # å»æ‰åºå·
                line = re.sub(r"^\d+[\.\)ã€]\s*", "", line)
                line = self._clean_text(line)
                if line and len(line) > 1:
                    lines.append(line)
            
            print(f"âœ… æˆåŠŸç¿»è¯‘ {len(lines)} å¥")
            return lines
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
            return []
    
    def _adjust_by_length(self, sentences, translations, target_lang):
        """è°ƒæ•´ç¿»è¯‘é•¿åº¦"""
        print(f"\nâœï¸  è°ƒæ•´ç¿»è¯‘é•¿åº¦...")
        
        adjusted = []
        lang_name = self._get_language_name(target_lang)
        
        for i, sent in enumerate(sentences):
            if i >= len(translations):
                continue
            
            text_orig = sent.get("text", "")
            text_trans = translations[i]
            
            target_words = max(3, len(text_orig) // 3)
            current_words = len(text_trans.split())
            
            print(f"  [{i+1}/{len(sentences)}] è¯æ•°: {current_words} â†’ ç›®æ ‡: {target_words}", end="\r")
            
            if abs(current_words - target_words) <= 3:
                adjusted_text = text_trans
            else:
                try:
                    prompt = f"""Adjust this {lang_name} sentence so that its length (word count) is close to {target_words} words.
Keep the same meaning, tone, and fluency.
Sentence: "{text_trans}"
Output only the adjusted sentence."""
                    
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": f"You are a fluent {lang_name} editor."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.4,
                        max_tokens=100
                    )
                    adjusted_text = self._clean_text(response.choices[0].message.content.strip())
                    if not adjusted_text:
                        adjusted_text = text_trans
                except Exception as e:
                    adjusted_text = text_trans
                
                time.sleep(0.2)
            
            adjusted.append(adjusted_text)
        
        print(f"\nâœ… é•¿åº¦è°ƒæ•´å®Œæˆ")
        return adjusted
    
    def _clean_text(self, text):
        """æ¸…ç†ç¿»è¯‘æ–‡æœ¬"""
        # ç§»é™¤ä¸­æ–‡å­—ç¬¦
        text = re.sub(r'[\u4e00-\u9fff]+', '', text)
        # ç§»é™¤ä¸­æ–‡æ ‡ç‚¹
        text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ã€Šã€‹ã€ã€‘ï¼ˆï¼‰]', '', text)
        # æ¸…ç†ç©ºæ ¼
        text = ' '.join(text.split())
        return text.strip()
    
    def _get_language_name(self, lang_code):
        """è·å–è¯­è¨€åç§°"""
        language_names = {
            "en": "English",
            "zh": "Chinese",
            "ja": "Japanese",
            "ko": "Korean",
            "fr": "French",
            "de": "German",
            "es": "Spanish",
            "ru": "Russian",
            "ar": "Arabic",
            "hi": "Hindi"
        }
        return language_names.get(lang_code, "English")