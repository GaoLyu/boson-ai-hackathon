import json
import os
import subprocess
import numpy as np
import soundfile as sf
from pathlib import Path

# =================== é…ç½® ===================
INPUT_JSON = "translated_with_timestamps.json"
INPUT_DIR = "generated_audio"
ALIGNED_DIR = os.path.join(INPUT_DIR, "aligned")
BGM_PATH = "/Users/fiona/boson-ai-hackathon/generated_audio/accompaniment.wav"
FINAL_SPEECH = os.path.join(INPUT_DIR, "speech_full.wav")
FINAL_MIXED = os.path.join(INPUT_DIR, "final_with_bgm.wav")

SAMPLE_RATE = 24000
CHANNELS = 1

# =================== å·¥å…·å‡½æ•° ===================
def ensure_dir(path):
    Path(path).mkdir(parents=True, exist_ok=True)

def get_audio_duration(path):
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration",
             "-of", "default=noprint_wrappers=1:nokey=1", path],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )
        return float(result.stdout.strip())
    except:
        return 0.0

def change_audio_speed(input_file, output_file, speed):
    """ä½¿ç”¨ ffmpeg æ”¹å˜æ’­æ”¾é€Ÿåº¦"""
    try:
        subprocess.run(
            ["ffmpeg", "-y", "-i", input_file, "-filter:a", f"atempo={speed}", output_file],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )
        return True
    except:
        return False

def pad_silence(input_file, output_file, pad_seconds):
    """åœ¨éŸ³é¢‘åè¡¥é™éŸ³"""
    try:
        subprocess.run(
            ["ffmpeg", "-y", "-i", input_file, "-af", f"apad=pad_dur={pad_seconds}", output_file],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )
        return True
    except:
        return False

def align_audio_to_duration(input_file, target_duration, output_file):
    """è°ƒæ•´æ¯æ®µéŸ³é¢‘æ—¶é•¿ä»¥å¯¹é½"""
    actual = get_audio_duration(input_file)
    if actual <= 0:
        print("âš ï¸ ç©ºéŸ³é¢‘ï¼Œè·³è¿‡ã€‚")
        return False

    ratio = target_duration / actual
    if 0.9 <= ratio <= 1.1:
        os.rename(input_file, output_file)
        print(f"  âœ… åŒ¹é…: {actual:.2f}s â‰ˆ {target_duration:.2f}s")
        return True

    if ratio > 1.1 and ratio < 2.0:
        speed = 1.0 / ratio
        print(f"  ğŸ• æ”¾æ…¢ {speed:.2f}x â†’ {target_duration:.2f}s")
        change_audio_speed(input_file, output_file, speed)
        return True
    elif ratio < 0.9 and ratio > 0.5:
        speed = 1.0 / ratio
        print(f"  â© åŠ é€Ÿ {speed:.2f}x â†’ {target_duration:.2f}s")
        change_audio_speed(input_file, output_file, speed)
        return True
    elif ratio >= 2.0:
        pad_silence(input_file, output_file, target_duration - actual)
        return True
    else:
        os.rename(input_file, output_file)
        return True

def assemble_full_audio(sentences, aligned_dir, output_path):
    """å°†å¯¹é½åçš„æ‰€æœ‰è¯­éŸ³æŒ‰æ—¶é—´æ‹¼æ¥æˆå®Œæ•´è½¨"""
    total_duration = sentences[-1]["end"]
    total_samples = int(total_duration * SAMPLE_RATE)
    full_wave = np.zeros(total_samples, dtype=np.float32)

    print(f"\nğŸ¬ æ‹¼æ¥è¯­éŸ³è½¨ï¼Œæ€»æ—¶é•¿ {total_duration:.2f}s")

    for i, sent in enumerate(sentences, 1):
        start = sent.get("start", 0)
        end = sent.get("end", 0)
        target_dur = end - start
        path = os.path.join(aligned_dir, f"aligned_{i:02d}.wav")
        if not os.path.exists(path):
            print(f"  âš ï¸ ç¼ºå¤± {path}ï¼Œè·³è¿‡ã€‚")
            continue

        # è¯»å–éŸ³é¢‘å¹¶æ’å…¥æ­£ç¡®ä½ç½®
        data, sr = sf.read(path)
        if sr != SAMPLE_RATE:
            print(f"  âš ï¸ é‡‡æ ·ç‡ä¸ç¬¦: {sr}ï¼Œè·³è¿‡ã€‚")
            continue

        start_idx = int(start * SAMPLE_RATE)
        end_idx = min(start_idx + len(data), len(full_wave))
        full_wave[start_idx:end_idx] += data[:end_idx - start_idx]

    # å†™å‡ºå®Œæ•´è¯­éŸ³è½¨
    sf.write(output_path, full_wave, SAMPLE_RATE)
    print(f"âœ… å·²ç”Ÿæˆå®Œæ•´è¯­éŸ³è½¨: {output_path}")

def mix_with_bgm(speech, bgm, output_path, volume=0.2):
    """æ··åˆè¯­éŸ³ä¸ç¯å¢ƒéŸ³"""
    if not os.path.exists(bgm):
        print(f"âš ï¸ æœªæ‰¾åˆ°èƒŒæ™¯éŸ³: {bgm}")
        return False
    try:
        subprocess.run(
            [
                "ffmpeg", "-y",
                "-i", speech,
                "-i", bgm,
                "-filter_complex",
                f"[1:a]volume={volume}[bgm];[0:a][bgm]amix=inputs=2:duration=longest",
                output_path
            ],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        print(f"âœ… å·²æ··åˆè¯­éŸ³ä¸èƒŒæ™¯éŸ³: {output_path}")
        return True
    except Exception as e:
        print(f"âŒ æ··éŸ³å¤±è´¥: {e}")
        return False

# =================== ä¸»ç¨‹åº ===================
def main():
    print("=" * 80)
    print("ğŸ¯ Step 3C: å¯¹é½ + æ‹¼æ¥ + èƒŒæ™¯æ··åˆ")
    print("=" * 80)

    ensure_dir(ALIGNED_DIR)

    if not os.path.exists(INPUT_JSON):
        print(f"âŒ æ‰¾ä¸åˆ° {INPUT_JSON}")
        return

    with open(INPUT_JSON, "r", encoding="utf-8") as f:
        data = json.load(f)
    sentences = data[0].get("sentence_info", [])
    print(f"âœ… åŠ è½½ {len(sentences)} æ®µè¯­éŸ³\n")

    # Step 1: å¯¹é½æ¯ä¸€æ®µ
    for i, sent in enumerate(sentences, 1):
        src = os.path.join(INPUT_DIR, f"english_{i:02d}.wav")
        dst = os.path.join(ALIGNED_DIR, f"aligned_{i:02d}.wav")
        if not os.path.exists(src):
            print(f"[{i:02d}] âŒ ç¼ºå¤± {src}")
            continue
        dur = sent.get("duration", 0)
        print(f"[{i:02d}] å¯¹é½: {Path(src).name} â†’ {dur:.2f}s")
        align_audio_to_duration(src, dur, dst)

    # Step 2: æ‹¼æ¥è¯­éŸ³è½¨
    assemble_full_audio(sentences, ALIGNED_DIR, FINAL_SPEECH)

    # Step 3: æ··åˆèƒŒæ™¯éŸ³
    if os.path.exists(BGM_PATH):
        mix_with_bgm(FINAL_SPEECH, BGM_PATH, FINAL_MIXED, volume=0.18)
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒéŸ³: {BGM_PATH}")

    print("\nğŸ‰ å…¨æµç¨‹å®Œæˆï¼")
    print(f"ğŸ—£ï¸ è¯­éŸ³è½¨: {FINAL_SPEECH}")
    print(f"ğŸŒ¿ æ··éŸ³ç»“æœ: {FINAL_MIXED}")
    print("=" * 80)

if __name__ == "__main__":
    main()
